{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: denseweight in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (2.2.2)\n",
      "Requirement already satisfied: KDEpy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (1.1.11)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (1.6.1)\n",
      "Requirement already satisfied: scipy<2.0,>=1.0.1 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from KDEpy->denseweight) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from scikit-learn->denseweight) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from scikit-learn->denseweight) (3.5.0)\n",
      "(1000000,)\n",
      "[0.00696068]\n",
      "[1.77102832]\n",
      "[2.20667524]\n",
      "[2.23723705]\n",
      "[2.23945467]\n",
      "[2.23945467]\n",
      "Train Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800000 entries, 0 to 799999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   Series1  800000 non-null  float64\n",
      " 1   Series2  800000 non-null  float64\n",
      " 2   Series3  800000 non-null  float64\n",
      " 3   Label    800000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 24.4 MB\n",
      "None\n",
      "\n",
      "Test Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   Series1  200000 non-null  float64\n",
      " 1   Series2  200000 non-null  float64\n",
      " 2   Series3  200000 non-null  float64\n",
      " 3   Label    200000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas -q\n",
    "!pip install denseweight\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from denseweight import DenseWeight\n",
    "\n",
    "\n",
    "# File paths\n",
    "train_file = \"./extraextra_lin_normalized_log1p_train_data.csv\"\n",
    "test_file = \"./extraextra_lin_normalized_log1p_test_data.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "dw = DenseWeight(alpha=1)\n",
    "print(pd.concat([train_df[\"Label\"], test_df[\"Label\"]]).to_numpy().shape)\n",
    "weights = dw.fit(pd.concat([train_df[\"Label\"], test_df[\"Label\"]]).to_numpy())\n",
    "train_weights = dw(train_df[\"Label\"].to_numpy())\n",
    "test_weights = dw(test_df[\"Label\"].to_numpy())\n",
    "\n",
    "print(dw([0.01]))\n",
    "print(dw([0.1]))\n",
    "print(dw([1]))\n",
    "print(dw([6]))\n",
    "print(dw([200]))\n",
    "print(dw([400]))\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Train Data:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series1</th>\n",
       "      <th>Series2</th>\n",
       "      <th>Series3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>8.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499820</td>\n",
       "      <td>0.500057</td>\n",
       "      <td>0.500170</td>\n",
       "      <td>2.498894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.219353</td>\n",
       "      <td>0.291573</td>\n",
       "      <td>0.291520</td>\n",
       "      <td>5.131788e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>0.252525</td>\n",
       "      <td>4.289651e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.499823</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>4.391191e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>3.308511e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.991320e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Series1        Series2        Series3         Label\n",
       "count  800000.000000  800000.000000  800000.000000  8.000000e+05\n",
       "mean        0.499820       0.500057       0.500170  2.498894e-01\n",
       "std         0.219353       0.291573       0.291520  5.131788e-01\n",
       "min         0.000000       0.000000       0.000000  0.000000e+00\n",
       "25%         0.387755       0.252525       0.252525  4.289651e-09\n",
       "50%         0.499823       0.494949       0.505051  4.391191e-02\n",
       "75%         0.612245       0.757576       0.757576  3.308511e-01\n",
       "max         1.000000       1.000000       1.000000  5.991320e+00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sinabs in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pbr in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (6.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (2.2.2)\n",
      "Requirement already satisfied: torch>=1.8 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (2.4.1)\n",
      "Requirement already satisfied: nir in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (1.0.4)\n",
      "Requirement already satisfied: nirtorch in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (1.0)\n",
      "Requirement already satisfied: samna>=0.33 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (0.41.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (2024.12.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from nir->sinabs) (3.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from jinja2->torch>=1.8->sinabs) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sympy->torch>=1.8->sinabs) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install norse and pytorch\n",
    "!pip install sinabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.inputval = dataframe[\"Series1\"]\n",
    "        self.mean = dataframe[\"Series2\"]\n",
    "        self.std = dataframe[\"Series3\"]\n",
    "        self.labels = dataframe[\"Label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputval)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputval = self.inputval.iloc[idx]\n",
    "        mean = self.mean.iloc[idx]\n",
    "        std = self.std.iloc[idx]\n",
    "        labels = self.labels.iloc[idx]\n",
    "        return inputval, mean, std, labels\n",
    "    \n",
    "# Create the datasets\n",
    "train_dataset = DataFrameDataset(train_df)\n",
    "test_dataset = DataFrameDataset(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "train_sampler = WeightedRandomSampler(weights=train_weights, num_samples=len(train_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input data\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128) #, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 132865\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "TRAINING_PREFIX = \"denseweight_1_0_extraextra_lin_normalized_256_2HL_normalized_log1p\"\n",
    "\n",
    "ann = nn.Sequential(\n",
    "    nn.Linear(3, 256),  # Input layer: 3 features (mu, sigma, x)\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),  # first hidden layer\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),  # second hidden layer\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 1)    # Output layer: single value for f(x; mu, sigma)\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "#ann.load_state_dict(torch.load(f\"results/{TRAINING_PREFIX}/ann_epoch_300.pth\"))\n",
    "\n",
    "ann.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in ann.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (spiking_model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "    (1): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (spike_output): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "  )\n",
       "  (analog_model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sinabs.from_torch import from_model\n",
    "\n",
    "num_time_steps_per_sample = 100\n",
    "\n",
    "sinabs_model = from_model(ann, input_shape=(3,), add_spiking_output=True, synops=False, num_timesteps=num_time_steps_per_sample)\n",
    "sinabs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torcheval -q\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "\n",
    "def create_loss_plot():\n",
    "    fig = go.FigureWidget()\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Train Loss', line=dict(color='blue')))\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Eval Loss', line=dict(color='orange')))\n",
    "\n",
    "    # Configure layout\n",
    "    fig.update_layout(title='Training and Evaluation Losses',\n",
    "                    xaxis_title='Epoch',\n",
    "                    yaxis_title='Loss',\n",
    "                    template='plotly_dark')\n",
    "\n",
    "    # Display the figure widget\n",
    "    display(fig)\n",
    "    return fig\n",
    "\n",
    "def update_loss_plot(fig, train_loss, eval_loss, from_epoch=0):\n",
    "    if from_epoch != 0:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(from_epoch, len(train_loss)))\n",
    "            fig.data[0].y = train_loss[from_epoch:]\n",
    "            fig.data[1].x = list(range(from_epoch, len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss[from_epoch:]\n",
    "    elif len(train_loss) < 30:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(len(train_loss)))\n",
    "            fig.data[0].y = train_loss\n",
    "            fig.data[1].x = list(range(len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss\n",
    "    else:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(len(train_loss) - 30, len(train_loss)))\n",
    "            fig.data[0].y = train_loss[-30:]\n",
    "            fig.data[1].x = list(range(len(eval_loss) - 30, len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss[-30:]        \n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "def gaussian_probability(x, y, z):\n",
    "    return (1 / (np.sqrt(2 * np.pi) * z)) * np.exp(-((x - y) ** 2) / (2 * z ** 2))\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def do_epoch(loader, model, optimizer, device, n_epochs: int, current_epoch: int, train: bool = False, scheduler=None):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    epoch_loss = 0\n",
    "    metric = R2Score(device=device)\n",
    "    for inputvals, means, stds, labels in tqdm(loader, desc=f\"{'Epoch' if train else 'Eval Epoch'} {current_epoch+1}/{n_epochs}\"):\n",
    "        inputs = torch.stack((inputvals, means, stds), dim=1).float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        metric.update(outputs.squeeze(), labels)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.huber_loss(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "        else:\n",
    "            loss = F.huber_loss(outputs.squeeze(), labels.float())\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # For Plateau scheduler\n",
    "    if scheduler is not None and not train:\n",
    "        print(\"sched step\")\n",
    "        scheduler.step(epoch_loss)\n",
    "    return epoch_loss, metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727a9fc6fb204bfe9850aec200f66686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '2fe0a135-ca04-4e56-80a7-0563d72655d0',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'orange'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Eval Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'c7876bab-ac8e-4135-aa10-ae24b8dbb569',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Training and Evaluation Losses'},\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1353e098c944c5e958a97f6b438d0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 90/1000:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3684e3e095be4209bb197d7eab6da1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 90/1000:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 90, LR: [6.25e-06], Train Loss: 0.006849382420511756, Diff: -8.88098355429981e-05, Eval Loss: 0.003244612449791698, Diff Eval: -4.477129102013061e-06, Train R2 Score: 0.9601941704750061, Eval R2 Score: 0.9677774906158447\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de53cb64f1640bdaaaed0d5d9dbe0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 91/1000:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374d1e9e40204519a6352713120373df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 91/1000:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 91, LR: [6.25e-06], Train Loss: 0.007014635311076563, Diff: 0.00016525289056480708, Eval Loss: 0.003251428134133353, Diff Eval: 6.815684341655252e-06, Train R2 Score: 0.9587728381156921, Eval R2 Score: 0.9675191640853882\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63aa5ae572b46e1a63a25449173e603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 92/1000:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3502977d0da9484998f1260aa8084cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 92/1000:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 92, LR: [6.25e-06], Train Loss: 0.006829648873676088, Diff: -0.00018498643740047505, Eval Loss: 0.0032666763014167115, Diff Eval: 1.524816728335843e-05, Train R2 Score: 0.9594624638557434, Eval R2 Score: 0.9678391218185425\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded964146e304ace96736eb9cb13e230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 93/1000:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5514d4e815b42489b66afe761be5b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 93/1000:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 93, LR: [6.25e-06], Train Loss: 0.0069584460946744, Diff: 0.00012879722099831247, Eval Loss: 0.0035771917454616286, Diff Eval: 0.0003105154440449171, Train R2 Score: 0.9592673182487488, Eval R2 Score: 0.9646190404891968\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00d2ba285c947e795e0abb3c786ee25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 94/1000:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6893113e4ec64a78a494bd140d88fbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 94/1000:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 94, LR: [6.25e-06], Train Loss: 0.006774140571880817, Diff: -0.00018430552279358366, Eval Loss: 0.0033770128163041445, Diff Eval: -0.0002001789291574841, Train R2 Score: 0.9598334431648254, Eval R2 Score: 0.96646648645401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dda0ad07534b958f27d58daebefa7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 95/1000:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288041da4c0347d9bc6b5471b31579f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 95/1000:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 95, LR: [6.25e-06], Train Loss: 0.006810826996888682, Diff: 3.668642500786502e-05, Eval Loss: 0.0032593916146696415, Diff Eval: -0.00011762120163450298, Train R2 Score: 0.9598965048789978, Eval R2 Score: 0.9674987196922302\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5f8b5f5b0847ffa682e2c81e0d8351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 96/1000:   0%|          | 0/6250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scheduler\n",
    "!pip install pytorch_warmup\n",
    "\n",
    "from pytorch_warmup import LinearWarmup\n",
    "\n",
    "# Train\n",
    "\n",
    "ann.train()\n",
    "\n",
    "N_EPOCHS = 1000\n",
    "LR = 0.0004\n",
    "SAVE_EVERY = 50\n",
    "\n",
    "# Create subfolder for this loop\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(f\"./results/{TRAINING_PREFIX}\"):\n",
    "    shutil.rmtree(f\"./results/{TRAINING_PREFIX}\")\n",
    "os.makedirs(f\"./results/{TRAINING_PREFIX}\")\n",
    "\n",
    "optim = torch.optim.AdamW(ann.parameters(), lr=LR)\n",
    "#optim = torch.optim.SGD(ann.parameters(), lr=LR)\n",
    "#opt_step = torch.compile(optim.step, mode=\"reduce-overhead\")\n",
    "\n",
    "num_steps = len(train_loader) * N_EPOCHS\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.25, patience=10, verbose=True)\n",
    "#    optim,\n",
    "#    milestones=[i * len(train_loader) for i in [250, 500]])\n",
    "#warmup_scheduler = LinearWarmup(optim, warmup_period=(len(train_loader) * 50) )\n",
    "\n",
    "\n",
    "last_loss = 0\n",
    "last_eval_loss = 0\n",
    "\n",
    "epoch_loss_list = []\n",
    "eval_loss_list = [] \n",
    "\n",
    "fig = create_loss_plot()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        clear_output(wait=True)\n",
    "        fig = create_loss_plot()\n",
    "        update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n",
    "    \n",
    "    epoch_loss, train_R2_score = do_epoch(train_loader, ann, optim, device, n_epochs=N_EPOCHS, current_epoch=epoch, train=True, scheduler=lr_scheduler)\n",
    "    eval_epoch_loss, eval_R2_score = do_epoch(test_loader, ann, None, device, n_epochs=N_EPOCHS, current_epoch=epoch, train=False, scheduler=lr_scheduler)\n",
    "    eval_loss_list.append(eval_epoch_loss/len(test_loader))\n",
    "    print(f\"Epoch {epoch+1}, LR: {lr_scheduler.get_last_lr()}, Train Loss: {epoch_loss/len(train_loader)}, Diff: {epoch_loss/len(train_loader) - last_loss}, Eval Loss: {eval_epoch_loss/len(test_loader)}, Diff Eval: {eval_epoch_loss/len(test_loader) - last_eval_loss}, Train R2 Score: {train_R2_score}, Eval R2 Score: {eval_R2_score}\")\n",
    "    last_loss = epoch_loss/len(train_loader)\n",
    "    last_eval_loss = eval_epoch_loss/len(test_loader)\n",
    "    epoch_loss_list.append(epoch_loss/len(train_loader))\n",
    "    update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        torch.save(ann.state_dict(), f\"./results/{TRAINING_PREFIX}/ann_epoch_{epoch}.pth\")\n",
    "    elif epoch == N_EPOCHS - 1:\n",
    "        torch.save(ann.state_dict(), f\"./results/{TRAINING_PREFIX}/ann_epoch_{epoch}.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ann.state_dict(), \"largerer_ann_new_data5.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8ad8e71a9b46ee96a488a0cfb3dff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '29098738-dc2b-4dde-a3c9-6405766ad9d4',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'orange'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Eval Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '0c64bd97-2f9b-42b0-820c-6b9d14926bf6',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Training and Evaluation Losses'},\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = create_loss_plot()\n",
    "update_loss_plot(fig, epoch_loss_list, eval_loss_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02354570327594876,\n",
       " 0.016079609875362368,\n",
       " 0.013032140182000584,\n",
       " 0.011524268243256957,\n",
       " 0.010171118808425963,\n",
       " 0.009753358722217382,\n",
       " 0.00949931381121045,\n",
       " 0.008910709847644903,\n",
       " 0.008775201361898799,\n",
       " 0.008207614116957411,\n",
       " 0.008266430261835921,\n",
       " 0.007838183197292965,\n",
       " 0.008113450737993699,\n",
       " 0.007735621863713022,\n",
       " 0.007821641203609762,\n",
       " 0.007920708534969017,\n",
       " 0.007775321107667405,\n",
       " 0.00760134226844646,\n",
       " 0.007880219091107138,\n",
       " 0.007694296670369804,\n",
       " 0.0071474009543657305,\n",
       " 0.007292596587599255,\n",
       " 0.006992759147346951,\n",
       " 0.0067663737699622285,\n",
       " 0.006963065523775294,\n",
       " 0.006801811356347753,\n",
       " 0.00693427745963214,\n",
       " 0.00679407113855239,\n",
       " 0.006699170251275645,\n",
       " 0.006832049342935206,\n",
       " 0.006571169172923546,\n",
       " 0.006604561636155704,\n",
       " 0.006860836541986792,\n",
       " 0.006776035700095818,\n",
       " 0.007147561122267507,\n",
       " 0.004572304146295646,\n",
       " 0.004483162216356722,\n",
       " 0.004515452351988061,\n",
       " 0.004457874274796341,\n",
       " 0.004530045843842672,\n",
       " 0.004508944094426697,\n",
       " 0.004500302514513024,\n",
       " 0.00448892230636091,\n",
       " 0.004555785058827605,\n",
       " 0.004524561919159023,\n",
       " 0.0045456524761870966,\n",
       " 0.0045211095549515445,\n",
       " 0.004522436461453326,\n",
       " 0.004583058625994017,\n",
       " 0.004552337364654523,\n",
       " 0.004538756286293501,\n",
       " 0.004553282194484491,\n",
       " 0.004591637137675425,\n",
       " 0.004512216260182904,\n",
       " 0.0044918492707650874,\n",
       " 0.0034319244065124078,\n",
       " 0.0032785777140513527,\n",
       " 0.0031707093644939596,\n",
       " 0.0031532082703278866,\n",
       " 0.002982161742501776,\n",
       " 0.0029832114587648537,\n",
       " 0.002936829194789752,\n",
       " 0.0029363324822980212,\n",
       " 0.0028382774312322727,\n",
       " 0.002874011553977616,\n",
       " 0.0029046296678698854,\n",
       " 0.002829078768649488,\n",
       " 0.002812575445714174,\n",
       " 0.0027473954813956518,\n",
       " 0.002847078844967182,\n",
       " 0.0027293665747204795,\n",
       " 0.0026831873671978247,\n",
       " 0.00261621756659064,\n",
       " 0.002793672986247111,\n",
       " 0.0026604460376012137,\n",
       " 0.0027033928192988967,\n",
       " 0.0027277793385589028,\n",
       " 0.0026709866052464348,\n",
       " 0.002562935613138252,\n",
       " 0.0026300324721512153,\n",
       " 0.002626315580921364,\n",
       " 0.002637135771823232,\n",
       " 0.002568085676203482,\n",
       " 0.0027787311623909045,\n",
       " 0.002584722950894502,\n",
       " 0.002712946364308591,\n",
       " 0.0026298840949009173,\n",
       " 0.002440683356494992,\n",
       " 0.0025239982127270195,\n",
       " 0.0025796208899770863,\n",
       " 0.0025435616018809376,\n",
       " 0.0024606657450750935,\n",
       " 0.0024860482330515514,\n",
       " 0.0024388994922774146,\n",
       " 0.0025133089976618066,\n",
       " 0.002651647032230394,\n",
       " 0.002514828493668465,\n",
       " 0.0025063981854420853,\n",
       " 0.002506761293776799,\n",
       " 0.001290834083603113,\n",
       " 0.0012037575461831876,\n",
       " 0.0012410781125194626,\n",
       " 0.001214623149735853,\n",
       " 0.00121024187287956,\n",
       " 0.0012042289226409048,\n",
       " 0.001195220067552873,\n",
       " 0.0012195417551754508,\n",
       " 0.001139962131791981,\n",
       " 0.0011076853242563084,\n",
       " 0.0011240837851469404,\n",
       " 0.00112288886654831,\n",
       " 0.0011381697484559845,\n",
       " 0.0011071557261480484,\n",
       " 0.001085735674072639,\n",
       " 0.0010870754479884637,\n",
       " 0.0010841736410971499,\n",
       " 0.001126922711734078,\n",
       " 0.0011391267971647904,\n",
       " 0.0010489237018488347,\n",
       " 0.0010890864912129472,\n",
       " 0.0010237909545033471,\n",
       " 0.0010744304044771706,\n",
       " 0.0011657070285599912,\n",
       " 0.001071663569281809,\n",
       " 0.0010220538706617662,\n",
       " 0.0010146445256884909,\n",
       " 0.0010161767354421318,\n",
       " 0.0010519142270670272,\n",
       " 0.0010690522673091618,\n",
       " 0.001072151799222338,\n",
       " 0.0010680100254673744,\n",
       " 0.001059105321073439,\n",
       " 0.001038473739193869,\n",
       " 0.0010401300465886015,\n",
       " 0.0010562460031540832,\n",
       " 0.0010571896741545061,\n",
       " 0.0010085108776891139,\n",
       " 0.0010195713093911762,\n",
       " 0.0009971209659246961,\n",
       " 0.001021202886441606,\n",
       " 0.0010426814626238775,\n",
       " 0.0010250314928661102,\n",
       " 0.0010110316311946373,\n",
       " 0.0006680872726795497,\n",
       " 0.0006614029597735498,\n",
       " 0.0006762700463511282,\n",
       " 0.0006606400648411364,\n",
       " 0.0006782746718131239,\n",
       " 0.0006473436788364779,\n",
       " 0.0006476176031155047,\n",
       " 0.0006449619118776172,\n",
       " 0.0006449804023915204,\n",
       " 0.0006325773898838088,\n",
       " 0.000643419843185693,\n",
       " 0.0006261116714734817,\n",
       " 0.000645180678521283,\n",
       " 0.0006329887714149663,\n",
       " 0.0006468260907335207,\n",
       " 0.0006263119722594274,\n",
       " 0.0006088384030008456,\n",
       " 0.0006287767168675783,\n",
       " 0.000629291616192204,\n",
       " 0.0006160309477796545,\n",
       " 0.0006210941496444866,\n",
       " 0.0006338749749446288,\n",
       " 0.0006097133847459918,\n",
       " 0.0006018146490934305,\n",
       " 0.0006104830953944474,\n",
       " 0.0006140041617670795,\n",
       " 0.0006092215398943517,\n",
       " 0.0005980463592975866,\n",
       " 0.0006207965034397784,\n",
       " 0.0006370429849356879,\n",
       " 0.0005198996991832973,\n",
       " 0.0005435657127341256,\n",
       " 0.0005314180126879364,\n",
       " 0.0005371713643125258,\n",
       " 0.0005280043202941306,\n",
       " 0.0005153179289848777,\n",
       " 0.0005409793233597884,\n",
       " 0.0005248625651292968,\n",
       " 0.0005273016951401951,\n",
       " 0.000535921815179172,\n",
       " 0.0005483136552711949,\n",
       " 0.0005434125887980917,\n",
       " 0.0005372593516373308,\n",
       " 0.0005388690545351711,\n",
       " 0.0005122554843424587,\n",
       " 0.0005312589354347437,\n",
       " 0.0005315636916074436,\n",
       " 0.0005202220380946528,\n",
       " 0.0005268170368252322,\n",
       " 0.0005265752127522137,\n",
       " 0.000496458923202008,\n",
       " 0.0004965526455885265,\n",
       " 0.0004938840289606014,\n",
       " 0.000489074035526719,\n",
       " 0.0005067550474073505,\n",
       " 0.0005119379873445723,\n",
       " 0.0004989246754965279,\n",
       " 0.0005062445255264174,\n",
       " 0.0005063847372063901,\n",
       " 0.0004922141953121172,\n",
       " 0.0005086596904677571,\n",
       " 0.0004981201685772976,\n",
       " 0.0005001187427010154,\n",
       " 0.0004952939618896926,\n",
       " 0.0005048577072907938,\n",
       " 0.0005119341350567993,\n",
       " 0.0004958059855236206,\n",
       " 0.0005054520915530156,\n",
       " 0.0004901713834365364,\n",
       " 0.0005019574766309233,\n",
       " 0.000503498108019121,\n",
       " 0.00048687390807899646,\n",
       " 0.0004911128373607062,\n",
       " 0.0005007546529837418,\n",
       " 0.0004966740791132907,\n",
       " 0.0004984198285947787,\n",
       " 0.0005052136893011629,\n",
       " 0.0005267202792118769,\n",
       " 0.0004901228834426729,\n",
       " 0.0005055652538861614,\n",
       " 0.0005033613324299222,\n",
       " 0.0004980696118116612,\n",
       " 0.0005097132982604672,\n",
       " 0.000501928614958888,\n",
       " 0.0004988397877314128,\n",
       " 0.0004870320971868932,\n",
       " 0.0004918291149497964,\n",
       " 0.0005038965816108976,\n",
       " 0.0005089975815615617,\n",
       " 0.0004952982123021502,\n",
       " 0.0005034424366930034,\n",
       " 0.00048732321142742874,\n",
       " 0.0005008726740325802,\n",
       " 0.0005052870670746779,\n",
       " 0.000495976724239299,\n",
       " 0.0004894087495555869,\n",
       " 0.0005059608849219512,\n",
       " 0.0004974028738879133,\n",
       " 0.0004951535171986325,\n",
       " 0.0004909597676043631,\n",
       " 0.0004852829718671273,\n",
       " 0.000492110436843941,\n",
       " 0.0004910187825991306,\n",
       " 0.0004955862601194531,\n",
       " 0.0004931382543145446,\n",
       " 0.0004900063116155798,\n",
       " 0.0005061016175319673,\n",
       " 0.0004984839044167893,\n",
       " 0.0005068943253112957,\n",
       " 0.0005002827280049678,\n",
       " 0.0004967447658692254,\n",
       " 0.0004956440207606647,\n",
       " 0.0004980110732890899,\n",
       " 0.0004934553412039532,\n",
       " 0.00048460969914624003,\n",
       " 0.0004957885177171556,\n",
       " 0.0005109982083766954,\n",
       " 0.0004974687241832725,\n",
       " 0.0005021814094489673,\n",
       " 0.0004859454462048598,\n",
       " 0.000507168639175361,\n",
       " 0.0004845406063558767,\n",
       " 0.0005147443723358447,\n",
       " 0.0005214358999574324,\n",
       " 0.000511919909651624,\n",
       " 0.0004951457380672218,\n",
       " 0.0005016559068829519,\n",
       " 0.0005133515280956636,\n",
       " 0.0005022773701307597,\n",
       " 0.0004762686582363676,\n",
       " 0.0005052671591792023,\n",
       " 0.0004932746431120904,\n",
       " 0.0004869288990908535,\n",
       " 0.0005045376146613853,\n",
       " 0.0005087817309220554,\n",
       " 0.0004999271844211034,\n",
       " 0.0005003774413041538,\n",
       " 0.0004823584583163029,\n",
       " 0.0005044821985188173,\n",
       " 0.0004987563441984822,\n",
       " 0.000493370423479937,\n",
       " 0.0005033106926834443,\n",
       " 0.0005072650259797228,\n",
       " 0.0004883756590046687,\n",
       " 0.000494821261370671,\n",
       " 0.0004985159275290789,\n",
       " 0.0004854295420809649,\n",
       " 0.0005001491162908496,\n",
       " 0.0005040519786515506,\n",
       " 0.0004995083595532924,\n",
       " 0.0004883743262360803,\n",
       " 0.0005095161184750031,\n",
       " 0.0005003021963039646,\n",
       " 0.0004978119666111888,\n",
       " 0.0004966754934692289,\n",
       " 0.000503202909512911,\n",
       " 0.0004947796770732384,\n",
       " 0.0004973364252410829,\n",
       " 0.0005012046056910185,\n",
       " 0.0004987854975153459,\n",
       " 0.0004988143795524956,\n",
       " 0.0005049506334261969,\n",
       " 0.0005007648651988711,\n",
       " 0.0004994646056223428,\n",
       " 0.0005052446082449751,\n",
       " 0.0005033374702814035,\n",
       " 0.0004904120633378625,\n",
       " 0.0004899643165315502,\n",
       " 0.0004979011597891804,\n",
       " 0.0004869668106647441,\n",
       " 0.0004979786601412343,\n",
       " 0.0004973673999588937,\n",
       " 0.0005046332348178839,\n",
       " 0.0004909684927441412,\n",
       " 0.0005016988578788005,\n",
       " 0.0004910298887389945,\n",
       " 0.0004921735328465002,\n",
       " 0.0004868529624043731,\n",
       " 0.0005054165252204985,\n",
       " 0.0004884020177356433,\n",
       " 0.0004827407744055381,\n",
       " 0.0005084620276541682,\n",
       " 0.0005011499077326152,\n",
       " 0.00048647038919269106,\n",
       " 0.00048661903289379553,\n",
       " 0.0005178497561335098,\n",
       " 0.00048638309714209754,\n",
       " 0.0004979206646390958,\n",
       " 0.0005025044124212581,\n",
       " 0.0004950461975944927,\n",
       " 0.0004925441960530588,\n",
       " 0.0005177259097353089,\n",
       " 0.0005031281285046135,\n",
       " 0.0004970684534928296,\n",
       " 0.0004858803722326411,\n",
       " 0.0004951548981998349,\n",
       " 0.0004898794150684262,\n",
       " 0.000493445418846095,\n",
       " 0.0004982549897034187,\n",
       " 0.000488972029472934,\n",
       " 0.0005105414146045223,\n",
       " 0.000488403416388901,\n",
       " 0.0004953249972028425,\n",
       " 0.000490598182354006,\n",
       " 0.0004963998426374747,\n",
       " 0.0005004848174832296,\n",
       " 0.0004889949286222691,\n",
       " 0.0004939486980839866,\n",
       " 0.0004942069950531004,\n",
       " 0.0004918019239493879,\n",
       " 0.0005068756505666533,\n",
       " 0.0004970205715869088,\n",
       " 0.0004960712060710648,\n",
       " 0.0004951896780205425,\n",
       " 0.0004921655571798328,\n",
       " 0.0005053902922844281,\n",
       " 0.0005022614021768095,\n",
       " 0.0004998382454615785,\n",
       " 0.0004901680724718608,\n",
       " 0.0005107971924409503,\n",
       " 0.0005135736296250252,\n",
       " 0.00048255835630057846,\n",
       " 0.0004935179561306722,\n",
       " 0.0004914574914309197,\n",
       " 0.00048573263727827,\n",
       " 0.0004993917873309693,\n",
       " 0.0005014943758002482,\n",
       " 0.0005012555688567227,\n",
       " 0.000492053969046101,\n",
       " 0.0004888909308583243,\n",
       " 0.00048131292272009886,\n",
       " 0.0004960275016346713,\n",
       " 0.0005082654055277816,\n",
       " 0.0004789153557462851,\n",
       " 0.0004941362951038172,\n",
       " 0.0005093032239569584,\n",
       " 0.0005021544215769973,\n",
       " 0.0005000472258776426,\n",
       " 0.0004903808710246812,\n",
       " 0.000502198081453098,\n",
       " 0.000494083418258233,\n",
       " 0.0004999554092361359,\n",
       " 0.0004783907467260724,\n",
       " 0.00048595884785463566,\n",
       " 0.000484482855743845,\n",
       " 0.0004935002005985007,\n",
       " 0.0005040803080162731,\n",
       " 0.0005017299805110088,\n",
       " 0.00048576736738614273,\n",
       " 0.0004923254101525526,\n",
       " 0.0005011282189987833,\n",
       " 0.0004937232021021191,\n",
       " 0.0005061308588559041,\n",
       " 0.0005069863659358816,\n",
       " 0.00048732428630522917,\n",
       " 0.00048337020120350644,\n",
       " 0.0004919195562106324,\n",
       " 0.0005062121994863265,\n",
       " 0.0004924764141667401,\n",
       " 0.0004929672330850736,\n",
       " 0.000507336633708328,\n",
       " 0.0004922719371283893,\n",
       " 0.0005062234413804254,\n",
       " 0.0004881125283212168,\n",
       " 0.00050390266193368,\n",
       " 0.0005191165146999992,\n",
       " 0.0005031410534778843,\n",
       " 0.0004914028188626981,\n",
       " 0.0005122673609905178,\n",
       " 0.000488705484525999,\n",
       " 0.000513764769420377,\n",
       " 0.000493784306566231,\n",
       " 0.0005050609152106335,\n",
       " 0.0005032472365652211,\n",
       " 0.0004868135838082526,\n",
       " 0.0004841071045625722,\n",
       " 0.0005071846400061623,\n",
       " 0.000504202837459743,\n",
       " 0.0004945340012171073,\n",
       " 0.000495503717440879,\n",
       " 0.00048626934067637194,\n",
       " 0.0004900612459285185,\n",
       " 0.00048398282272100915,\n",
       " 0.00047969175139965953,\n",
       " 0.0004969377557054394,\n",
       " 0.0004960771677736193,\n",
       " 0.0004816198921308387,\n",
       " 0.000493284703186946,\n",
       " 0.0005006803225894691,\n",
       " 0.0004995910544338403,\n",
       " 0.0005099474761798046,\n",
       " 0.0004897276158741442,\n",
       " 0.0004873888158774935,\n",
       " 0.0004969180069339927,\n",
       " 0.0004983618119027232,\n",
       " 0.0004963412585278275,\n",
       " 0.0005030939713283442,\n",
       " 0.0005037524130987003,\n",
       " 0.0005009707035508472,\n",
       " 0.000494478016316425,\n",
       " 0.0004998536974610761,\n",
       " 0.0005000045988778584,\n",
       " 0.0005050548413547221,\n",
       " 0.0005039616007811856,\n",
       " 0.000498393801357015,\n",
       " 0.00048061485054844524,\n",
       " 0.0004979782095301198,\n",
       " 0.0005051671278401045,\n",
       " 0.0005010601240373217,\n",
       " 0.0005025694439845393,\n",
       " 0.00048107071997306776]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f\"./extraextra_lin_normalized_log1p_scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8993888616979944)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.eval()\n",
    "transformed = scaler.transform([[0.5, 0.5, 0.5]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7978845608028654)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(4.639858601185763)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform([[0.1, 0.1, 0.1]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.989422804014327)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.1, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(42.19871407709524)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform([[0.01, 0.01, 0.01]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(39.894228040143275)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.01, 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.4602683311757058)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform([[0.9, 0.9, 0.9]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.44326920044603635)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.9, 0.9, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5615511663070611)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform([[0.9, 0.7, 0.1]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.53990966513188)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.9, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(3.9600567582951856)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform([[0.643, 0.7, 0.1]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.3912431320419234)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.643, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.0002111121305020598)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform([[4, 0.3, 0.2]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.57716245835995e-75)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(4, 0.3, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56565657, 0.38383838, 0.24242424, 0.71717172, 0.90909091,\n",
       "       0.25252525, 0.09090909, 0.52525253, 0.57575758, 0.72727273,\n",
       "       0.67676768, 0.33333333, 0.54545455, 0.85858586, 0.01010101,\n",
       "       0.84848485, 0.02020202, 0.08080808, 0.6969697 , 0.8989899 ,\n",
       "       0.63636364, 0.28282828, 0.14141414, 0.03030303, 0.23232323,\n",
       "       0.87878788, 0.41414141, 0.3030303 , 0.31313131, 0.27272727,\n",
       "       0.68686869, 0.39393939, 0.5959596 , 0.45454545, 0.19191919,\n",
       "       0.76767677, 0.93939394, 0.06060606, 0.73737374, 0.07070707,\n",
       "       0.43434343, 0.16161616, 0.48484848, 0.44444444, 0.86868687,\n",
       "       0.18181818, 0.49494949, 0.1010101 , 0.82828283, 0.97979798,\n",
       "       0.13131313, 1.        , 0.2020202 , 0.64646465, 0.74747475,\n",
       "       0.58585859, 0.62626263, 0.50505051, 0.35353535, 0.51515152,\n",
       "       0.94949495, 0.77777778, 0.83838384, 0.11111111, 0.34343434,\n",
       "       0.66666667, 0.75757576, 0.88888889, 0.70707071, 0.53535354,\n",
       "       0.42424242, 0.78787879, 0.21212121, 0.80808081, 0.81818182,\n",
       "       0.        , 0.17171717, 0.22222222, 0.95959596, 0.32323232,\n",
       "       0.91919192, 0.92929293, 0.98989899, 0.55555556, 0.96969697,\n",
       "       0.65656566, 0.04040404, 0.7979798 , 0.4040404 , 0.37373737,\n",
       "       0.15151515, 0.36363636, 0.60606061, 0.26262626, 0.05050505,\n",
       "       0.12121212, 0.46464646, 0.29292929, 0.61616162, 0.47474747])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.mean.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68686869, 0.23232323, 0.15151515, 0.92929293, 0.57575758,\n",
       "       0.97979798, 0.        , 0.93939394, 0.04040404, 0.03030303,\n",
       "       0.98989899, 0.54545455, 0.09090909, 0.42424242, 0.56565657,\n",
       "       0.34343434, 0.14141414, 0.26262626, 0.01010101, 0.55555556,\n",
       "       0.71717172, 0.81818182, 0.5959596 , 0.45454545, 0.47474747,\n",
       "       0.11111111, 0.60606061, 0.61616162, 0.43434343, 0.6969697 ,\n",
       "       0.75757576, 0.46464646, 0.82828283, 0.32323232, 0.16161616,\n",
       "       0.91919192, 0.18181818, 0.29292929, 0.63636364, 0.76767677,\n",
       "       0.96969697, 0.58585859, 0.74747475, 0.86868687, 0.36363636,\n",
       "       0.90909091, 0.88888889, 0.12121212, 0.27272727, 0.73737374,\n",
       "       0.62626263, 0.65656566, 0.49494949, 0.87878788, 0.1010101 ,\n",
       "       0.77777778, 0.8989899 , 0.17171717, 0.2020202 , 0.48484848,\n",
       "       0.08080808, 0.94949495, 0.24242424, 0.50505051, 0.41414141,\n",
       "       0.66666667, 0.31313131, 0.39393939, 0.25252525, 0.37373737,\n",
       "       0.05050505, 0.51515152, 0.21212121, 0.33333333, 1.        ,\n",
       "       0.83838384, 0.35353535, 0.02020202, 0.3030303 , 0.22222222,\n",
       "       0.84848485, 0.38383838, 0.7979798 , 0.52525253, 0.80808081,\n",
       "       0.44444444, 0.64646465, 0.28282828, 0.67676768, 0.78787879,\n",
       "       0.07070707, 0.95959596, 0.19191919, 0.70707071, 0.13131313,\n",
       "       0.06060606, 0.4040404 , 0.72727273, 0.85858586, 0.53535354])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.std.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.23997641710620973)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# std 1.25 and mean -3.04\n",
    "transformed = scaler.transform([[-2, -3.04, 1.25]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22578002723581)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(-2, -3.04, 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(261.7693535578953)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform([[0.999, 1, 0.001]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(241.97072451914318)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.999, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning:\n",
      "\n",
      "X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(395.1356436863128)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = scaler.transform([[1, 1, 0.001]])\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(398.94228040143275)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(1, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
