{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: denseweight in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (2.2.2)\n",
      "Requirement already satisfied: KDEpy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (1.1.11)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (1.6.1)\n",
      "Requirement already satisfied: scipy<2.0,>=1.0.1 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from KDEpy->denseweight) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from scikit-learn->denseweight) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from scikit-learn->denseweight) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000,)\n",
      "[0.49257702]\n",
      "[1.60334578]\n",
      "[1.91920806]\n",
      "[1.92240712]\n",
      "[1.92347052]\n",
      "[1.92347052]\n",
      "Train Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800000 entries, 0 to 799999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   Series1  800000 non-null  float64\n",
      " 1   Series2  800000 non-null  float64\n",
      " 2   Series3  800000 non-null  float64\n",
      " 3   Label    800000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 24.4 MB\n",
      "None\n",
      "\n",
      "Test Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   Series1  200000 non-null  float64\n",
      " 1   Series2  200000 non-null  float64\n",
      " 2   Series3  200000 non-null  float64\n",
      " 3   Label    200000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas -q\n",
    "!pip install denseweight\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from denseweight import DenseWeight\n",
    "\n",
    "\n",
    "# File paths\n",
    "train_file = \"./extraextra_lin_unchangedinp_log1p_larger_range_train_data.csv\"\n",
    "test_file = \"./extraextra_lin_unchangedinp_log1p_larger_range_test_data.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "dw = DenseWeight(alpha=0.75)\n",
    "print(pd.concat([train_df[\"Label\"], test_df[\"Label\"]]).to_numpy().shape)\n",
    "weights = dw.fit(pd.concat([train_df[\"Label\"], test_df[\"Label\"]]).to_numpy())\n",
    "train_weights = dw(train_df[\"Label\"].to_numpy())\n",
    "test_weights = dw(test_df[\"Label\"].to_numpy())\n",
    "\n",
    "print(dw([0.01]))\n",
    "print(dw([0.1]))\n",
    "print(dw([1]))\n",
    "print(dw([6]))\n",
    "print(dw([200]))\n",
    "print(dw([400]))\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Train Data:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series1</th>\n",
       "      <th>Series2</th>\n",
       "      <th>Series3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>8.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.006782</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>1.571831</td>\n",
       "      <td>1.203007e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.269194</td>\n",
       "      <td>1.832007</td>\n",
       "      <td>0.915544</td>\n",
       "      <td>3.929215e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-18.849556</td>\n",
       "      <td>-3.141593</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.231533</td>\n",
       "      <td>-1.554930</td>\n",
       "      <td>0.794079</td>\n",
       "      <td>1.329654e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.006544</td>\n",
       "      <td>-0.031733</td>\n",
       "      <td>1.587158</td>\n",
       "      <td>1.420751e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.231533</td>\n",
       "      <td>1.618396</td>\n",
       "      <td>2.380237</td>\n",
       "      <td>1.176513e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.849556</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>5.991320e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Series1        Series2        Series3         Label\n",
       "count  800000.000000  800000.000000  800000.000000  8.000000e+05\n",
       "mean       -0.006782       0.000357       1.571831  1.203007e-01\n",
       "std         8.269194       1.832007       0.915544  3.929215e-01\n",
       "min       -18.849556      -3.141593       0.001000  0.000000e+00\n",
       "25%        -4.231533      -1.554930       0.794079  1.329654e-09\n",
       "50%        -0.006544      -0.031733       1.587158  1.420751e-02\n",
       "75%         4.231533       1.618396       2.380237  1.176513e-01\n",
       "max        18.849556       3.141593       3.141593  5.991320e+00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sinabs in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pbr in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (6.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (2.2.2)\n",
      "Requirement already satisfied: torch>=1.8 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (2.4.1)\n",
      "Requirement already satisfied: nir in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (1.0.4)\n",
      "Requirement already satisfied: nirtorch in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (1.0)\n",
      "Requirement already satisfied: samna>=0.33 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (0.41.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (2024.12.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from nir->sinabs) (3.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from jinja2->torch>=1.8->sinabs) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sympy->torch>=1.8->sinabs) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install norse and pytorch\n",
    "!pip install sinabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.inputval = dataframe[\"Series1\"]\n",
    "        self.mean = dataframe[\"Series2\"]\n",
    "        self.std = dataframe[\"Series3\"]\n",
    "        self.labels = dataframe[\"Label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputval)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputval = self.inputval.iloc[idx]\n",
    "        mean = self.mean.iloc[idx]\n",
    "        std = self.std.iloc[idx]\n",
    "        labels = self.labels.iloc[idx]\n",
    "        return inputval, mean, std, labels\n",
    "    \n",
    "# Create the datasets\n",
    "train_dataset = DataFrameDataset(train_df)\n",
    "test_dataset = DataFrameDataset(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "train_sampler = WeightedRandomSampler(weights=train_weights, num_samples=len(train_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input data\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # , sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64) #, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 132865\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "TRAINING_PREFIX = \"extraextra_lin_256_2HL_unchanged_larger_ranges_log1p_adamw\"\n",
    "\n",
    "ann = nn.Sequential(\n",
    "    nn.Linear(3, 256),  # Input layer: 3 features (mu, sigma, x)\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),  # first hidden layer\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),  # second hidden layer\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 1)    # Output layer: single value for f(x; mu, sigma)\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "#ann.load_state_dict(torch.load(f\"results/{TRAINING_PREFIX}/ann_epoch_300.pth\"))\n",
    "\n",
    "ann.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in ann.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (spiking_model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "    (1): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (spike_output): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "  )\n",
       "  (analog_model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sinabs.from_torch import from_model\n",
    "\n",
    "num_time_steps_per_sample = 100\n",
    "\n",
    "sinabs_model = from_model(ann, input_shape=(3,), add_spiking_output=True, synops=False, num_timesteps=num_time_steps_per_sample)\n",
    "sinabs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torcheval -q\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "\n",
    "def create_loss_plot():\n",
    "    fig = go.FigureWidget()\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Train Loss', line=dict(color='blue')))\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Eval Loss', line=dict(color='orange')))\n",
    "\n",
    "    # Configure layout\n",
    "    fig.update_layout(title='Training and Evaluation Losses',\n",
    "                    xaxis_title='Epoch',\n",
    "                    yaxis_title='Loss',\n",
    "                    template='plotly_dark')\n",
    "\n",
    "    # Display the figure widget\n",
    "    display(fig)\n",
    "    return fig\n",
    "\n",
    "def update_loss_plot(fig, train_loss, eval_loss, from_epoch=0):\n",
    "    if from_epoch != 0:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(from_epoch, len(train_loss)))\n",
    "            fig.data[0].y = train_loss[from_epoch:]\n",
    "            fig.data[1].x = list(range(from_epoch, len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss[from_epoch:]\n",
    "    elif len(train_loss) < 30:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(len(train_loss)))\n",
    "            fig.data[0].y = train_loss\n",
    "            fig.data[1].x = list(range(len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss\n",
    "    else:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(len(train_loss) - 30, len(train_loss)))\n",
    "            fig.data[0].y = train_loss[-30:]\n",
    "            fig.data[1].x = list(range(len(eval_loss) - 30, len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss[-30:]        \n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "def gaussian_probability(x, y, z):\n",
    "    return (1 / (np.sqrt(2 * np.pi) * z)) * np.exp(-((x - y) ** 2) / (2 * z ** 2))\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def do_epoch(loader, model, optimizer, device, n_epochs: int, current_epoch: int, train: bool = False, scheduler=None):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    epoch_loss = 0\n",
    "    metric = R2Score(device=device)\n",
    "    for inputvals, means, stds, labels in tqdm(loader, desc=f\"{'Epoch' if train else 'Eval Epoch'} {current_epoch+1}/{n_epochs}\"):\n",
    "        inputs = torch.stack((inputvals, means, stds), dim=1).float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        metric.update(outputs.squeeze(), labels)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.huber_loss(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "        else:\n",
    "            loss = F.huber_loss(outputs.squeeze(), labels.float())\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # For Plateau scheduler\n",
    "    if scheduler is not None and not train:\n",
    "        print(\"sched step\")\n",
    "        scheduler.step(epoch_loss)\n",
    "    return epoch_loss, metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750717887a784820b3487a0fb852cdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ef7d00ee-d38d-4a34-9b0d-6b4ea723d68b',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'orange'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Eval Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'fa793452-ab0f-4538-975e-21653622f0ca',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Training and Evaluation Losses'},\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23eae937666748f4af63505fc4a95508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 420/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683de1969e174629af0a46d1f908c8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 420/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 420, LR: [3.90625e-07], Train Loss: 0.002862327992984076, Diff: -9.75148747847654e-07, Eval Loss: 0.002863111865540095, Diff Eval: 1.4890723576436223e-05, Train R2 Score: 0.9498990774154663, Eval R2 Score: 0.9501832127571106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554d2045c52e4463bb3886e4163edcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 421/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6518d196e14c46609ebaa8383ec9da9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 421/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 421, LR: [3.90625e-07], Train Loss: 0.002859322320039056, Diff: -3.0056729450199555e-06, Eval Loss: 0.0028334015228184397, Diff Eval: -2.9710342721655375e-05, Train R2 Score: 0.9500166773796082, Eval R2 Score: 0.9507512450218201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7c2f49365542a4bcfbcd3ed26b011d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 422/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6966b5d9582341c5a26906e4b95e9a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 422/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 422, LR: [3.90625e-07], Train Loss: 0.0028614776509759575, Diff: 2.155330936901359e-06, Eval Loss: 0.0028347315609555243, Diff Eval: 1.3300381370845438e-06, Train R2 Score: 0.9499385952949524, Eval R2 Score: 0.9506910443305969\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7332974f0a4a8c96cf2e5536c694b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 423/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77af10053d734de88cccfab69a898cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 423/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 423, LR: [3.90625e-07], Train Loss: 0.0028608679413064065, Diff: -6.097096695509285e-07, Eval Loss: 0.0028433531699829247, Diff Eval: 8.621609027400449e-06, Train R2 Score: 0.949950098991394, Eval R2 Score: 0.9506316184997559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9547f10670d7481bb9cc3efcbe96f44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 424/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60907d6e7864b178b178e97f96e05e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 424/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 424, LR: [3.90625e-07], Train Loss: 0.002858498906167507, Diff: -2.369035138899498e-06, Eval Loss: 0.002839918344202833, Diff Eval: -3.434825780091518e-06, Train R2 Score: 0.9500254392623901, Eval R2 Score: 0.950657844543457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0659198aef54b6a9a251c4762ed2db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 425/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b25d60eeb64d0c9125efc2544be881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 425/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 425, LR: [3.90625e-07], Train Loss: 0.002859054554343945, Diff: 5.556481764380436e-07, Eval Loss: 0.0028331066671130477, Diff Eval: -6.811677089785511e-06, Train R2 Score: 0.9500351548194885, Eval R2 Score: 0.9508169293403625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb1d1c712f6445ebfecd929012f8268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 426/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d12b96cc62472ebab68fe759f88be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 426/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 426, LR: [3.90625e-07], Train Loss: 0.002853871605808024, Diff: -5.182948535921092e-06, Eval Loss: 0.002829593583474343, Diff Eval: -3.5130836387045963e-06, Train R2 Score: 0.9501646757125854, Eval R2 Score: 0.9508382081985474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c3d5f0665c485089394ca9f7f5a246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 427/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c7abc54da7488f868b7023593feb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 427/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 427, LR: [3.90625e-07], Train Loss: 0.002856834562911364, Diff: 2.9629571033401754e-06, Eval Loss: 0.0028493191577917015, Diff Eval: 1.972557431735838e-05, Train R2 Score: 0.9500832557678223, Eval R2 Score: 0.950402557849884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d0bf6d93de4d908e28309ae81ef6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 428/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17490e0402940cba3344b09109429e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 428/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 428, LR: [3.90625e-07], Train Loss: 0.002855398017069839, Diff: -1.4365458415252497e-06, Eval Loss: 0.0028320339343936483, Diff Eval: -1.7285223398053225e-05, Train R2 Score: 0.9500868320465088, Eval R2 Score: 0.9507648348808289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27ae4c38eec4758acde4d4a092b91d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 429/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3facf6cc04c346d39d95bf42493849ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 429/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 429, LR: [3.90625e-07], Train Loss: 0.0028529667513735343, Diff: -2.431265696304589e-06, Eval Loss: 0.002830969811330874, Diff Eval: -1.06412306277422e-06, Train R2 Score: 0.9501802325248718, Eval R2 Score: 0.9508301615715027\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad789d7a45184f80a4de498dd01d7f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 430/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba1c29e615648ec806bf04944c488e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 430/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 430, LR: [3.90625e-07], Train Loss: 0.0028541720582592996, Diff: 1.2053068857652803e-06, Eval Loss: 0.00284028129551376, Diff Eval: 9.311484182885753e-06, Train R2 Score: 0.950111448764801, Eval R2 Score: 0.9507927894592285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4a428cb4cc4a039b3975c99585d556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 431/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff7cf39029149e9a93226c29f667975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 431/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 431, LR: [3.90625e-07], Train Loss: 0.002854443661071922, Diff: 2.716028126223402e-07, Eval Loss: 0.002831368850738327, Diff Eval: -8.912444775432873e-06, Train R2 Score: 0.9501609206199646, Eval R2 Score: 0.9509443044662476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff310f5385cb48dbb24bfcd14ac70bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 432/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c91f54cd3cb43fda7a39bfaa055921c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 432/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 432, LR: [3.90625e-07], Train Loss: 0.0028518298448613247, Diff: -2.6138162105972078e-06, Eval Loss: 0.002838793877619237, Diff Eval: 7.425026880909964e-06, Train R2 Score: 0.9502153396606445, Eval R2 Score: 0.9506224989891052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f50fe14ad14455dbde1d4b7a5a647e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 433/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd48fa48c959493882179d6f955b0900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 433/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 433, LR: [3.90625e-07], Train Loss: 0.0028502128345965945, Diff: -1.6170102647302363e-06, Eval Loss: 0.002828527222655648, Diff Eval: -1.0266654963588667e-05, Train R2 Score: 0.9502307772636414, Eval R2 Score: 0.9508417844772339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a738e318bb4695949c03ce1b370d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 434/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scheduler\n",
    "!pip install pytorch_warmup\n",
    "\n",
    "from pytorch_warmup import LinearWarmup\n",
    "\n",
    "# Train\n",
    "\n",
    "ann.train()\n",
    "\n",
    "N_EPOCHS = 1000\n",
    "LR = 0.0016\n",
    "SAVE_EVERY = 50\n",
    "\n",
    "# Create subfolder for this loop\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(f\"./results/{TRAINING_PREFIX}\"):\n",
    "    shutil.rmtree(f\"./results/{TRAINING_PREFIX}\")\n",
    "os.makedirs(f\"./results/{TRAINING_PREFIX}\")\n",
    "\n",
    "optim = torch.optim.AdamW(ann.parameters(), lr=LR)\n",
    "#optim = torch.optim.SGD(ann.parameters(), lr=LR)\n",
    "#opt_step = torch.compile(optim.step, mode=\"reduce-overhead\")\n",
    "\n",
    "num_steps = len(train_loader) * N_EPOCHS\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.25, patience=10, verbose=True)\n",
    "#    optim,\n",
    "#    milestones=[i * len(train_loader) for i in [250, 500]])\n",
    "#warmup_scheduler = LinearWarmup(optim, warmup_period=(len(train_loader) * 50) )\n",
    "\n",
    "\n",
    "last_loss = 0\n",
    "last_eval_loss = 0\n",
    "\n",
    "epoch_loss_list = []\n",
    "eval_loss_list = [] \n",
    "\n",
    "fig = create_loss_plot()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        clear_output(wait=True)\n",
    "        fig = create_loss_plot()\n",
    "        update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n",
    "    \n",
    "    epoch_loss, train_R2_score = do_epoch(train_loader, ann, optim, device, n_epochs=N_EPOCHS, current_epoch=epoch, train=True, scheduler=lr_scheduler)\n",
    "    eval_epoch_loss, eval_R2_score = do_epoch(test_loader, ann, None, device, n_epochs=N_EPOCHS, current_epoch=epoch, train=False, scheduler=lr_scheduler)\n",
    "    eval_loss_list.append(eval_epoch_loss/len(test_loader))\n",
    "    print(f\"Epoch {epoch+1}, LR: {lr_scheduler.get_last_lr()}, Train Loss: {epoch_loss/len(train_loader)}, Diff: {epoch_loss/len(train_loader) - last_loss}, Eval Loss: {eval_epoch_loss/len(test_loader)}, Diff Eval: {eval_epoch_loss/len(test_loader) - last_eval_loss}, Train R2 Score: {train_R2_score}, Eval R2 Score: {eval_R2_score}\")\n",
    "    last_loss = epoch_loss/len(train_loader)\n",
    "    last_eval_loss = eval_epoch_loss/len(test_loader)\n",
    "    epoch_loss_list.append(epoch_loss/len(train_loader))\n",
    "    update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        torch.save(ann.state_dict(), f\"./results/{TRAINING_PREFIX}/ann_epoch_{epoch}.pth\")\n",
    "    elif epoch == N_EPOCHS - 1:\n",
    "        torch.save(ann.state_dict(), f\"./results/{TRAINING_PREFIX}/ann_epoch_{epoch}.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ann.state_dict(), \"largerer_ann_new_data5.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86aa2106be0b45bdb7f26065f9104065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '6c0504d7-16bb-41b8-975d-82ba5e5f2547',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'orange'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Eval Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '482614b7-0ffe-474c-bc86-1962277ccb6d',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Training and Evaluation Losses'},\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = create_loss_plot()\n",
    "update_loss_plot(fig, epoch_loss_list, eval_loss_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010720561613654717,\n",
       " 0.005650727769082005,\n",
       " 0.004973712196938722,\n",
       " 0.0046965876476417175,\n",
       " 0.00449116287927187,\n",
       " 0.0044736452529025705,\n",
       " 0.00434148402540508,\n",
       " 0.004304189840590843,\n",
       " 0.0043479884606443375,\n",
       " 0.004332168479999127,\n",
       " 0.004299884850940253,\n",
       " 0.004254439220912136,\n",
       " 0.00421730754099568,\n",
       " 0.004236685128641839,\n",
       " 0.004213748104372171,\n",
       " 0.004182607872355438,\n",
       " 0.004251838786280278,\n",
       " 0.004290557541898742,\n",
       " 0.0042712727683148115,\n",
       " 0.004242378014136594,\n",
       " 0.004250861869595573,\n",
       " 0.00425550736627858,\n",
       " 0.004341588957470994,\n",
       " 0.004267976844588484,\n",
       " 0.004295712128373216,\n",
       " 0.004355830985663124,\n",
       " 0.004358745869377599,\n",
       " 0.004367734752605648,\n",
       " 0.00434205544977729,\n",
       " 0.004377770489534632,\n",
       " 0.004356311271676313,\n",
       " 0.004363446383026967,\n",
       " 0.004342417285856391,\n",
       " 0.004399272141062902,\n",
       " 0.0034898571438213275,\n",
       " 0.0034030793314072253,\n",
       " 0.0033154675950014824,\n",
       " 0.0032616962320990662,\n",
       " 0.0032274479818930014,\n",
       " 0.0031887777890863343,\n",
       " 0.0032312808225748086,\n",
       " 0.003186244974969286,\n",
       " 0.003142077289710269,\n",
       " 0.00308836991676656,\n",
       " 0.0031501268893878477,\n",
       " 0.003071829233619901,\n",
       " 0.0029613876231700123,\n",
       " 0.003046518387771257,\n",
       " 0.0029380126937618932,\n",
       " 0.0030288542428452683,\n",
       " 0.0030546892481252597,\n",
       " 0.0029646702727787032,\n",
       " 0.0030064654080283254,\n",
       " 0.0030260115353737183,\n",
       " 0.0030802285160188604,\n",
       " 0.0029367349491015195,\n",
       " 0.0030331810249846513,\n",
       " 0.00297229657743118,\n",
       " 0.0030732204344043113,\n",
       " 0.002909453926165297,\n",
       " 0.00184349636336643,\n",
       " 0.0017160288140423382,\n",
       " 0.0015598136733186402,\n",
       " 0.0014594584704786667,\n",
       " 0.0013332908442240342,\n",
       " 0.0012450950796732377,\n",
       " 0.0011444517665917737,\n",
       " 0.001060498289376419,\n",
       " 0.0010143048225399525,\n",
       " 0.000955357102511034,\n",
       " 0.0009120352109900022,\n",
       " 0.0008752627270322592,\n",
       " 0.0008094612775091082,\n",
       " 0.0008079577795239493,\n",
       " 0.000763949306862894,\n",
       " 0.0007500941465135429,\n",
       " 0.0007228015683492026,\n",
       " 0.0007297985522217391,\n",
       " 0.0006582179470357642,\n",
       " 0.0006751064126622032,\n",
       " 0.0006846386920454893,\n",
       " 0.0006546963591514327,\n",
       " 0.0006815935342161356,\n",
       " 0.0006542214366541247,\n",
       " 0.0006417413698175779,\n",
       " 0.000621875602766313,\n",
       " 0.0006503423117648617,\n",
       " 0.0006129660248641812,\n",
       " 0.000615235631977414,\n",
       " 0.0006256206214607232,\n",
       " 0.0006053321898488184,\n",
       " 0.0006551957366780903,\n",
       " 0.0006051111730948355,\n",
       " 0.0005843598928037113,\n",
       " 0.0005910947048317053,\n",
       " 0.0006113600998177821,\n",
       " 0.0006438753259391069,\n",
       " 0.000629602965288384,\n",
       " 0.0005978604883869718,\n",
       " 0.000636985878706896,\n",
       " 0.0006012841819844516,\n",
       " 0.00018267336533823254,\n",
       " 0.0001631900251425634,\n",
       " 0.00016717481145168676,\n",
       " 0.00015694541484265529,\n",
       " 0.00015004518034111925,\n",
       " 0.00015315259225040336,\n",
       " 0.00014081366308454107,\n",
       " 0.00014297546666125073,\n",
       " 0.0001337579521171108,\n",
       " 0.0001340661371391434,\n",
       " 0.00013834412695478592,\n",
       " 0.00013286465521852506,\n",
       " 0.0001172896072239314,\n",
       " 0.0001237464316686021,\n",
       " 0.00012384136137300175,\n",
       " 0.00011643460283375248,\n",
       " 0.00011238737982460065,\n",
       " 0.0001172820877514414,\n",
       " 0.00010693193067884977,\n",
       " 0.0001089576289405818,\n",
       " 0.00010776645113508493,\n",
       " 0.00010393397301816549,\n",
       " 0.0001043362967618782,\n",
       " 0.0001036409627409057,\n",
       " 0.00010703349560175866,\n",
       " 9.359548743123924e-05,\n",
       " 0.00010266407553799581,\n",
       " 9.68008532481349e-05,\n",
       " 0.00010209574919498436,\n",
       " 9.755636151672548e-05,\n",
       " 9.364272464742499e-05,\n",
       " 9.86687701237645e-05,\n",
       " 9.617749976765594e-05,\n",
       " 9.507210747539603e-05,\n",
       " 9.193859858106748e-05,\n",
       " 9.058578733135051e-05,\n",
       " 8.64509479573985e-05,\n",
       " 9.490511625287012e-05,\n",
       " 8.476853810535658e-05,\n",
       " 8.994246299861743e-05,\n",
       " 8.516817408393764e-05,\n",
       " 9.050679859113871e-05,\n",
       " 8.741182018037761e-05,\n",
       " 8.541700191943733e-05,\n",
       " 8.491416762915037e-05,\n",
       " 3.4421263824119704e-05,\n",
       " 3.475893044564259e-05,\n",
       " 3.430956794316671e-05,\n",
       " 3.297109081779354e-05,\n",
       " 3.173341648723408e-05,\n",
       " 3.0374414407033328e-05,\n",
       " 3.093695383490172e-05,\n",
       " 3.013446979256969e-05,\n",
       " 2.994647807871388e-05,\n",
       " 2.814771394649142e-05,\n",
       " 2.761098283572551e-05,\n",
       " 2.7176190330926603e-05,\n",
       " 2.7096875873182853e-05,\n",
       " 2.5595360680869135e-05,\n",
       " 2.5407193301892904e-05,\n",
       " 2.4431439763727668e-05,\n",
       " 2.41158107243632e-05,\n",
       " 2.3446837196228215e-05,\n",
       " 2.3912399833156998e-05,\n",
       " 2.3202088841128443e-05,\n",
       " 2.209166133810072e-05,\n",
       " 2.1796723137177877e-05,\n",
       " 2.1456598681770627e-05,\n",
       " 2.140583123196393e-05,\n",
       " 2.1273583708218666e-05,\n",
       " 2.0698757811928773e-05,\n",
       " 2.007247258868574e-05,\n",
       " 2.0717660513000738e-05,\n",
       " 1.9344990570393746e-05,\n",
       " 1.907428295860427e-05,\n",
       " 1.8646634142669427e-05,\n",
       " 1.8726091495547053e-05,\n",
       " 1.789589729404497e-05,\n",
       " 1.8358605774783427e-05,\n",
       " 1.6908809254139213e-05,\n",
       " 1.7107906305243433e-05,\n",
       " 1.7021809972250138e-05,\n",
       " 1.6603028366535e-05,\n",
       " 1.6656845672038115e-05,\n",
       " 1.589361759000326e-05,\n",
       " 1.573801918917866e-05,\n",
       " 1.5632811077497308e-05,\n",
       " 1.5559528403102833e-05,\n",
       " 1.593589722815068e-05,\n",
       " 1.4896928024239741e-05,\n",
       " 1.455879374970209e-05,\n",
       " 1.452666095301197e-05,\n",
       " 1.4078343846464349e-05,\n",
       " 1.3917984975913668e-05,\n",
       " 1.3689369793712559e-05,\n",
       " 1.3719519843467652e-05,\n",
       " 1.3910536031293077e-05,\n",
       " 1.301622953242827e-05,\n",
       " 1.285610302737382e-05,\n",
       " 1.3666899186293904e-05,\n",
       " 1.2347088362431578e-05,\n",
       " 1.2677487856889229e-05,\n",
       " 1.2628551480321448e-05,\n",
       " 1.216059090139197e-05,\n",
       " 1.198275836805692e-05,\n",
       " 1.147809002290046e-05,\n",
       " 1.1913253593705804e-05,\n",
       " 1.1554218301821493e-05,\n",
       " 1.1769420330822413e-05,\n",
       " 1.1077285618272298e-05,\n",
       " 1.1208546145956007e-05,\n",
       " 1.0960982157453145e-05,\n",
       " 1.1410174030570488e-05,\n",
       " 1.0801883878517629e-05,\n",
       " 1.174143986221111e-05,\n",
       " 1.0912637924911905e-05,\n",
       " 1.0355892537888849e-05,\n",
       " 1.0440128692891904e-05,\n",
       " 1.025417301975267e-05,\n",
       " 9.82614200357034e-06,\n",
       " 1.0338459985625832e-05,\n",
       " 1.0025779492905258e-05,\n",
       " 9.832214912694325e-06,\n",
       " 1.0272864939745433e-05,\n",
       " 1.0032300457514793e-05,\n",
       " 1.0178155619593099e-05,\n",
       " 9.260079799364576e-06,\n",
       " 9.538542826732055e-06,\n",
       " 9.65167221737488e-06,\n",
       " 9.272985937849399e-06,\n",
       " 9.26714209670763e-06,\n",
       " 9.22906836289144e-06,\n",
       " 8.970321130941556e-06,\n",
       " 9.27971194710608e-06,\n",
       " 4.8132048072727684e-06,\n",
       " 4.795268452965047e-06,\n",
       " 4.774090203979995e-06,\n",
       " 4.790852576838915e-06,\n",
       " 4.6668195705194645e-06,\n",
       " 4.6967457990319874e-06,\n",
       " 4.611796371194714e-06,\n",
       " 4.604558005825084e-06,\n",
       " 4.672780097645273e-06,\n",
       " 4.603137559653305e-06,\n",
       " 4.561007293482362e-06,\n",
       " 4.480921623317044e-06,\n",
       " 4.543634175347506e-06,\n",
       " 4.399732775393659e-06,\n",
       " 4.439075351067458e-06,\n",
       " 4.42161280109076e-06,\n",
       " 4.448634041644936e-06,\n",
       " 4.36789581539415e-06,\n",
       " 4.349547003522502e-06,\n",
       " 4.386371868688457e-06,\n",
       " 4.27633903316746e-06,\n",
       " 4.320954802313963e-06,\n",
       " 4.327605683055253e-06,\n",
       " 4.28584959044656e-06,\n",
       " 4.2201263328718144e-06,\n",
       " 4.152029621532165e-06,\n",
       " 4.212134129866172e-06,\n",
       " 4.222588404967383e-06,\n",
       " 4.1882995562059475e-06,\n",
       " 4.1569635022653984e-06,\n",
       " 4.149941028902049e-06,\n",
       " 4.0820482115816505e-06,\n",
       " 4.110760004550684e-06,\n",
       " 3.996303315982459e-06,\n",
       " 4.067647214046701e-06,\n",
       " 4.017645031328811e-06,\n",
       " 4.0273909063364496e-06,\n",
       " 3.98881892043164e-06,\n",
       " 4.046696944106998e-06,\n",
       " 4.0175497385541805e-06,\n",
       " 3.909262199019849e-06,\n",
       " 3.908800654850211e-06,\n",
       " 3.891540430840905e-06,\n",
       " 3.83066515158589e-06,\n",
       " 3.8465079486877585e-06,\n",
       " 3.845464650970598e-06,\n",
       " 3.7966114048322197e-06,\n",
       " 3.827032141682594e-06,\n",
       " 3.7517501658589937e-06,\n",
       " 3.770440705352485e-06,\n",
       " 3.760935466521005e-06,\n",
       " 3.748481523564351e-06,\n",
       " 3.7103169606280063e-06,\n",
       " 3.7827599128047494e-06,\n",
       " 3.682715759970279e-06,\n",
       " 3.668435034741151e-06,\n",
       " 3.6835795277897885e-06,\n",
       " 3.628783342802535e-06,\n",
       " 3.6887857639408138e-06,\n",
       " 3.740937085084397e-06,\n",
       " 3.602136635338411e-06,\n",
       " 3.6176239451640413e-06,\n",
       " 3.6689033111406388e-06,\n",
       " 3.590714193126132e-06,\n",
       " 3.5859998816658843e-06,\n",
       " 3.557359777402098e-06,\n",
       " 3.5043281313642184e-06,\n",
       " 3.5942240444865093e-06,\n",
       " 3.5153074459969957e-06,\n",
       " 3.4765552158341963e-06,\n",
       " 3.531245229959268e-06,\n",
       " 3.4807454466806573e-06,\n",
       " 3.528904183689292e-06,\n",
       " 3.4419772127535e-06,\n",
       " 3.46310053422485e-06,\n",
       " 3.436128786053132e-06,\n",
       " 3.3503342625874664e-06,\n",
       " 3.3981114079983856e-06,\n",
       " 3.4307862102957644e-06,\n",
       " 3.3798092432709836e-06,\n",
       " 3.369514593957774e-06,\n",
       " 3.3231110931239983e-06,\n",
       " 3.30352730082609e-06,\n",
       " 3.2998060160139176e-06,\n",
       " 3.3303435067421107e-06,\n",
       " 3.2436085542235558e-06,\n",
       " 3.3086448975723216e-06,\n",
       " 3.3255856765686074e-06,\n",
       " 3.242440043680972e-06,\n",
       " 3.311062264423299e-06,\n",
       " 3.2441501426512785e-06,\n",
       " 3.272094320078622e-06,\n",
       " 3.277093806531184e-06,\n",
       " 3.2300256753865143e-06,\n",
       " 3.2256181545403707e-06,\n",
       " 3.243902430290291e-06,\n",
       " 3.2078024834913776e-06,\n",
       " 3.221032563009203e-06,\n",
       " 3.1504538664955815e-06,\n",
       " 3.1247620197450486e-06,\n",
       " 3.101960140073743e-06,\n",
       " 3.1609395437681086e-06,\n",
       " 3.0859218208718175e-06,\n",
       " 3.0846478153455335e-06,\n",
       " 3.0448150161612377e-06,\n",
       " 3.0879048354620408e-06,\n",
       " 3.0648799870414225e-06,\n",
       " 3.0720783638514606e-06,\n",
       " 3.078276668327362e-06,\n",
       " 3.0574231578077617e-06,\n",
       " 3.0122679081136993e-06,\n",
       " 3.074805804335483e-06,\n",
       " 3.094616614886263e-06,\n",
       " 2.6021255480372927e-06,\n",
       " 2.6161752694508778e-06,\n",
       " 2.606805458669896e-06,\n",
       " 2.604741078694133e-06,\n",
       " 2.6031113888609526e-06,\n",
       " 2.599072953846644e-06,\n",
       " 2.5941141182499904e-06,\n",
       " 2.592781084397302e-06,\n",
       " 2.5899126933541082e-06,\n",
       " 2.5843810127366852e-06,\n",
       " 2.5974998256424442e-06,\n",
       " 2.5833338225584158e-06,\n",
       " 2.58528830830187e-06,\n",
       " 2.5828124714610113e-06,\n",
       " 2.5078547311693456e-06,\n",
       " 2.50521235484257e-06,\n",
       " 2.50831921514191e-06,\n",
       " 2.504589054574353e-06,\n",
       " 2.5020596529441265e-06,\n",
       " 2.501678116381072e-06,\n",
       " 2.5020578960175042e-06,\n",
       " 2.502783585425732e-06,\n",
       " 2.504786191665289e-06,\n",
       " 2.500254336976013e-06,\n",
       " 2.5044238018563193e-06,\n",
       " 2.5006624406341873e-06,\n",
       " 2.4983748279657903e-06,\n",
       " 2.500499348714129e-06,\n",
       " 2.503804917123489e-06,\n",
       " 2.5048461005599164e-06,\n",
       " 2.4967346480150353e-06,\n",
       " 2.486132366725542e-06,\n",
       " 2.482258740127463e-06,\n",
       " 2.480909985334847e-06,\n",
       " 2.4793984840937356e-06,\n",
       " 2.479175087597696e-06,\n",
       " 2.480354804658873e-06,\n",
       " 2.479112117899831e-06,\n",
       " 2.4794240648952837e-06,\n",
       " 2.4808730944050692e-06,\n",
       " 2.478504066623373e-06,\n",
       " 2.4797800283965897e-06,\n",
       " 2.4791101336279554e-06,\n",
       " 2.4796542204938987e-06,\n",
       " 2.48058505898598e-06,\n",
       " 2.47938029245347e-06,\n",
       " 2.4799106356010727e-06,\n",
       " 2.4813126222716165e-06,\n",
       " 2.4798733446630193e-06,\n",
       " 2.4775256958525913e-06,\n",
       " 2.4816170956296444e-06,\n",
       " 2.4797269426903766e-06,\n",
       " 2.47777856343987e-06,\n",
       " 2.4799542136884157e-06,\n",
       " 2.479486580014054e-06,\n",
       " 2.4800628641287403e-06,\n",
       " 2.4811681247058457e-06,\n",
       " 2.4783852897746783e-06,\n",
       " 2.4796437693419195e-06,\n",
       " 2.4797079858421966e-06,\n",
       " 2.4808655577680837e-06,\n",
       " 2.4787044505171707e-06,\n",
       " 2.480763344174193e-06,\n",
       " 2.479675005241688e-06,\n",
       " 2.4815668279541116e-06,\n",
       " 2.479466137735926e-06,\n",
       " 2.481852148134749e-06,\n",
       " 2.480511875070306e-06,\n",
       " 2.4801275337790683e-06,\n",
       " 2.479591740160458e-06,\n",
       " 2.479563965982834e-06,\n",
       " 2.4802435747596974e-06,\n",
       " 2.4787264783913087e-06,\n",
       " 2.481345517196587e-06,\n",
       " 2.4808357643985347e-06,\n",
       " 2.480138568126904e-06,\n",
       " 2.4815791652258666e-06,\n",
       " 2.4809461082850247e-06,\n",
       " 2.4802337531480134e-06,\n",
       " 2.4800891730728836e-06,\n",
       " 2.478741727571787e-06,\n",
       " 2.478576508169681e-06,\n",
       " 2.4785480152741e-06,\n",
       " 2.4796744482114264e-06,\n",
       " 2.479011762961818e-06,\n",
       " 2.4814149945666486e-06,\n",
       " 2.4800839943759458e-06,\n",
       " 2.4796285253989936e-06,\n",
       " 2.4787888859577835e-06,\n",
       " 2.4783814803140557e-06,\n",
       " 2.4801244123648305e-06,\n",
       " 2.480097222069162e-06,\n",
       " 2.4802727415601568e-06,\n",
       " 2.4809209019053924e-06,\n",
       " 2.481276905897403e-06,\n",
       " 2.481184651506965e-06,\n",
       " 2.4799798851984176e-06,\n",
       " 2.4796368862280362e-06,\n",
       " 2.481231445387948e-06,\n",
       " 2.481819918276642e-06,\n",
       " 2.4793952584559518e-06,\n",
       " 2.4783099875435253e-06,\n",
       " 2.48080373042626e-06,\n",
       " 2.4785395836295265e-06,\n",
       " 2.481076902747645e-06,\n",
       " 2.480329050594037e-06,\n",
       " 2.4805161539165966e-06,\n",
       " 2.4784370232043785e-06,\n",
       " 2.480296195341225e-06,\n",
       " 2.478989220494441e-06,\n",
       " 2.4822091542739598e-06,\n",
       " 2.4787388890331385e-06,\n",
       " 2.4803282908578696e-06,\n",
       " 2.4786434407087653e-06,\n",
       " 2.478094680726599e-06,\n",
       " 2.4764068488934753e-06,\n",
       " 2.478572518847386e-06,\n",
       " 2.480054590032523e-06,\n",
       " 2.4797082458553634e-06,\n",
       " 2.4797357895727144e-06,\n",
       " 2.479513428684186e-06,\n",
       " 2.4800046006657795e-06,\n",
       " 2.4791108680381056e-06,\n",
       " 2.48085955776105e-06,\n",
       " 2.479129665127857e-06,\n",
       " 2.478854273314255e-06,\n",
       " 2.4774641149076615e-06,\n",
       " 2.478501558430253e-06,\n",
       " 2.480549570788071e-06,\n",
       " 2.479215171655369e-06,\n",
       " 2.481463440548168e-06,\n",
       " 2.4787528374895374e-06,\n",
       " 2.479190628220067e-06,\n",
       " 2.4780629913902884e-06,\n",
       " 2.4807550894604446e-06,\n",
       " 2.4787405881329507e-06,\n",
       " 2.480118657612138e-06,\n",
       " 2.480401940036927e-06,\n",
       " 2.4800158084565285e-06,\n",
       " 2.4805117500932285e-06,\n",
       " 2.4800079998419735e-06,\n",
       " 2.479475668125133e-06,\n",
       " 2.4798986859798333e-06,\n",
       " 2.4804432284258836e-06,\n",
       " 2.4794967856973925e-06,\n",
       " 2.481119109077099e-06,\n",
       " 2.4807078600747447e-06,\n",
       " 2.4801869497980532e-06,\n",
       " 2.479553006220385e-06,\n",
       " 2.4808299646167597e-06,\n",
       " 2.478261118045566e-06,\n",
       " 2.480983938811505e-06,\n",
       " 2.48111403398525e-06,\n",
       " 2.480878765832131e-06,\n",
       " 2.4801202786943576e-06,\n",
       " 2.4802367464462806e-06,\n",
       " 2.4781035998296375e-06,\n",
       " 2.4797651918368046e-06,\n",
       " 2.47902316288787e-06,\n",
       " 2.480877392761158e-06,\n",
       " 2.4807314082590894e-06,\n",
       " 2.480331968451992e-06,\n",
       " 2.477653684841243e-06,\n",
       " 2.4792650211827548e-06,\n",
       " 2.4794188242606198e-06,\n",
       " 2.4797962335117063e-06,\n",
       " 2.4791686576747905e-06,\n",
       " 2.479969399013271e-06,\n",
       " 2.479655892741448e-06,\n",
       " 2.4783791557661063e-06,\n",
       " 2.4816154543066205e-06,\n",
       " 2.4806090995070916e-06,\n",
       " 2.4794722473177445e-06,\n",
       " 2.4798711582218404e-06,\n",
       " 2.4793931410636104e-06,\n",
       " 2.478298852819307e-06,\n",
       " 2.480626285459948e-06,\n",
       " 2.480863106297875e-06,\n",
       " 2.4784400876671953e-06,\n",
       " 2.4788049832466186e-06,\n",
       " 2.4789758377846738e-06,\n",
       " 2.480609950843018e-06,\n",
       " 2.479737846870194e-06,\n",
       " 2.47834395741279e-06,\n",
       " 2.481614127730154e-06,\n",
       " 2.478529319033669e-06,\n",
       " 2.4821323388584913e-06,\n",
       " 2.4809097345985264e-06,\n",
       " 2.479955847202291e-06,\n",
       " 2.4801082924079766e-06,\n",
       " 2.4827463837164033e-06,\n",
       " 2.4822118064514596e-06,\n",
       " 2.4794670811206743e-06,\n",
       " 2.479152867181256e-06,\n",
       " 2.4798764767024296e-06,\n",
       " 2.478779310184791e-06,\n",
       " 2.480123962328662e-06,\n",
       " 2.4794367952995342e-06,\n",
       " 2.482523627804767e-06,\n",
       " 2.4813698379045946e-06,\n",
       " 2.481314743237135e-06,\n",
       " 2.479045699518565e-06,\n",
       " 2.4818478536963085e-06,\n",
       " 2.4815961670094565e-06,\n",
       " 2.481571070318296e-06,\n",
       " 2.480101500383398e-06,\n",
       " 2.4804397971911383e-06,\n",
       " 2.4807356664246073e-06,\n",
       " 2.4806953430129397e-06,\n",
       " 2.479872465594326e-06,\n",
       " 2.4791708495092734e-06,\n",
       " 2.47914311265049e-06,\n",
       " 2.4810769629300468e-06,\n",
       " 2.4803290440388535e-06,\n",
       " 2.481125228136989e-06,\n",
       " 2.4830583646439663e-06,\n",
       " 2.4806085605951014e-06,\n",
       " 2.4794304170848135e-06,\n",
       " 2.4803417934117534e-06,\n",
       " 2.481013343088989e-06,\n",
       " 2.479932481398919e-06,\n",
       " 2.4810704813558002e-06,\n",
       " 2.4809510016780224e-06,\n",
       " 2.4815333342473877e-06,\n",
       " 2.481179050157607e-06,\n",
       " 2.4811037189465424e-06,\n",
       " 2.481700567311691e-06,\n",
       " 2.48081438265217e-06,\n",
       " 2.4789325882443336e-06,\n",
       " 2.481799553070232e-06,\n",
       " 2.4803271770338144e-06,\n",
       " 2.480354696755285e-06,\n",
       " 2.4807402371482113e-06,\n",
       " 2.4806123472819764e-06,\n",
       " 2.479659924496218e-06,\n",
       " 2.48249046212095e-06,\n",
       " 2.480630788511462e-06,\n",
       " 2.4808224807657096e-06,\n",
       " 2.4794630494557167e-06,\n",
       " 2.4816120573700574e-06,\n",
       " 2.478991134721582e-06,\n",
       " 2.480597480157485e-06,\n",
       " 2.4813695060777265e-06,\n",
       " 2.481939266955351e-06,\n",
       " 2.4810548142204425e-06,\n",
       " 2.4797923053426984e-06,\n",
       " 2.480936229429744e-06,\n",
       " 2.4801017554716507e-06,\n",
       " 2.4816616166435777e-06,\n",
       " 2.4821714890413203e-06,\n",
       " 2.479509812211518e-06,\n",
       " 2.481675787998938e-06,\n",
       " 2.4786037066235166e-06,\n",
       " 2.4806247424317007e-06,\n",
       " 2.48219517065877e-06,\n",
       " 2.4816610295602004e-06,\n",
       " 2.479685329557242e-06,\n",
       " 2.4796796679970613e-06,\n",
       " 2.4827846293715085e-06,\n",
       " 2.481203381544219e-06,\n",
       " 2.4788274543448095e-06,\n",
       " 2.480042211145701e-06,\n",
       " 2.481090053719299e-06,\n",
       " 2.481456218361018e-06,\n",
       " 2.4819131931280936e-06,\n",
       " 2.4806054621080875e-06,\n",
       " 2.481339242665399e-06,\n",
       " 2.4791870941101023e-06,\n",
       " 2.4791346782092204e-06,\n",
       " 2.481567205942383e-06,\n",
       " 2.4815328033298558e-06,\n",
       " 2.479997907435063e-06,\n",
       " 2.479497121643135e-06,\n",
       " 2.4826019692170577e-06,\n",
       " 2.481036230385598e-06,\n",
       " 2.4786972853576117e-06,\n",
       " 2.4785341557287664e-06,\n",
       " 2.4789792502122053e-06,\n",
       " 2.4819147860046087e-06,\n",
       " 2.479941211724963e-06,\n",
       " 2.4802616053909787e-06,\n",
       " 2.479790812515148e-06,\n",
       " 2.47953544039774e-06,\n",
       " 2.4808864073258974e-06,\n",
       " 2.48064817587192e-06,\n",
       " 2.4809669595163087e-06,\n",
       " 2.479228256747774e-06,\n",
       " 2.4804650074509028e-06,\n",
       " 2.482023615413027e-06,\n",
       " 2.4801942891951965e-06,\n",
       " 2.4803137463572966e-06,\n",
       " 2.4807599306120666e-06,\n",
       " 2.480943917219065e-06,\n",
       " 2.479148530354678e-06,\n",
       " 2.4792946161608144e-06,\n",
       " 2.4811931709893998e-06,\n",
       " 2.4802272803549384e-06,\n",
       " 2.4805581666021228e-06,\n",
       " 2.482212228493381e-06,\n",
       " 2.479237240772818e-06,\n",
       " 2.480282015112607e-06,\n",
       " 2.4811758639748403e-06,\n",
       " 2.4788247785966176e-06,\n",
       " 2.4808354032541046e-06,\n",
       " 2.4817638151216668e-06,\n",
       " 2.4817148833085413e-06,\n",
       " 2.480250081775921e-06]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7985268002609114)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.eval()\n",
    "transformed = [[0.5, 0.5, 0.5]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7978845608028654)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.9791190668689422)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.1, 0.1, 0.1]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.989422804014327)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.1, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(41.86783290284835)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.01, 0.01, 0.01]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(39.894228040143275)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.01, 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4408715498811401)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.9, 0.9, 0.9]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.44326920044603635)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.9, 0.9, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5431544288899663)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.9, 0.7, 0.1]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.53990966513188)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.9, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.3789679900971876)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.643, 0.7, 0.1]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.3912431320419234)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.643, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.908748968321537e-05)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[4, 0.3, 0.2]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.57716245835995e-75)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(4, 0.3, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13131313, -0.23232323, -0.51515152,  0.43434343,  0.81818182,\n",
       "       -0.49494949, -0.81818182,  0.05050505,  0.15151515,  0.45454545,\n",
       "        0.35353535, -0.33333333,  0.09090909,  0.71717172, -0.97979798,\n",
       "        0.6969697 , -0.95959596, -0.83838384,  0.39393939,  0.7979798 ,\n",
       "        0.27272727, -0.43434343, -0.71717172, -0.93939394, -0.53535354,\n",
       "        0.75757576, -0.17171717, -0.39393939, -0.37373737, -0.45454545,\n",
       "        0.37373737, -0.21212121,  0.19191919, -0.09090909, -0.61616162,\n",
       "        0.53535354,  0.87878788, -0.87878788,  0.47474747, -0.85858586,\n",
       "       -0.13131313, -0.67676768, -0.03030303, -0.11111111,  0.73737374,\n",
       "       -0.63636364, -0.01010101, -0.7979798 ,  0.65656566,  0.95959596,\n",
       "       -0.73737374,  1.        , -0.5959596 ,  0.29292929,  0.49494949,\n",
       "        0.17171717,  0.25252525,  0.01010101, -0.29292929,  0.03030303,\n",
       "        0.8989899 ,  0.55555556,  0.67676768, -0.77777778, -0.31313131,\n",
       "        0.33333333,  0.51515152,  0.77777778,  0.41414141,  0.07070707,\n",
       "       -0.15151515,  0.57575758, -0.57575758,  0.61616162,  0.63636364,\n",
       "       -1.        , -0.65656566, -0.55555556,  0.91919192, -0.35353535,\n",
       "        0.83838384,  0.85858586,  0.97979798,  0.11111111,  0.93939394,\n",
       "        0.31313131, -0.91919192,  0.5959596 , -0.19191919, -0.25252525,\n",
       "       -0.6969697 , -0.27272727,  0.21212121, -0.47474747, -0.8989899 ,\n",
       "       -0.75757576, -0.07070707, -0.41414141,  0.23232323, -0.05050505])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.mean.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68718182, 0.23309091, 0.15236364, 0.92936364, 0.57618182,\n",
       "       0.97981818, 0.001     , 0.93945455, 0.04136364, 0.03127273,\n",
       "       0.98990909, 0.54590909, 0.09181818, 0.42481818, 0.56609091,\n",
       "       0.34409091, 0.14227273, 0.26336364, 0.01109091, 0.556     ,\n",
       "       0.71745455, 0.81836364, 0.59636364, 0.45509091, 0.47527273,\n",
       "       0.112     , 0.60645455, 0.61654545, 0.43490909, 0.69727273,\n",
       "       0.75781818, 0.46518182, 0.82845455, 0.32390909, 0.16245455,\n",
       "       0.91927273, 0.18263636, 0.29363636, 0.63672727, 0.76790909,\n",
       "       0.96972727, 0.58627273, 0.74772727, 0.86881818, 0.36427273,\n",
       "       0.90918182, 0.889     , 0.12209091, 0.27345455, 0.73763636,\n",
       "       0.62663636, 0.65690909, 0.49545455, 0.87890909, 0.10190909,\n",
       "       0.778     , 0.89909091, 0.17254545, 0.20281818, 0.48536364,\n",
       "       0.08172727, 0.94954545, 0.24318182, 0.50554545, 0.41472727,\n",
       "       0.667     , 0.31381818, 0.39454545, 0.25327273, 0.37436364,\n",
       "       0.05145455, 0.51563636, 0.21290909, 0.334     , 1.        ,\n",
       "       0.83854545, 0.35418182, 0.02118182, 0.30372727, 0.223     ,\n",
       "       0.84863636, 0.38445455, 0.79818182, 0.52572727, 0.80827273,\n",
       "       0.445     , 0.64681818, 0.28354545, 0.67709091, 0.78809091,\n",
       "       0.07163636, 0.95963636, 0.19272727, 0.70736364, 0.13218182,\n",
       "       0.06154545, 0.40463636, 0.72754545, 0.85872727, 0.53581818])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.std.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.20334854540768302)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# std 1.25 and mean -3.04\n",
    "transformed = [[-2, -3.04, 1.25]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22578002723581)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(-2, -3.04, 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(242.76307435675864)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.999, 1, 0.001]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(241.97072451914318)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.999, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(397.1416407205497)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[1, 1, 0.001]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(398.94228040143275)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(1, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
