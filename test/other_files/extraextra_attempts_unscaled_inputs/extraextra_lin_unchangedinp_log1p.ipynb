{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: denseweight in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (2.2.2)\n",
      "Requirement already satisfied: KDEpy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (1.1.11)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from denseweight) (1.6.1)\n",
      "Requirement already satisfied: scipy<2.0,>=1.0.1 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from KDEpy->denseweight) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from scikit-learn->denseweight) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from scikit-learn->denseweight) (3.5.0)\n",
      "(1000000,)\n",
      "[0.43140687]\n",
      "[1.44147439]\n",
      "[1.69091653]\n",
      "[1.70841557]\n",
      "[1.70968533]\n",
      "[1.70968533]\n",
      "Train Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800000 entries, 0 to 799999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   Series1  800000 non-null  float64\n",
      " 1   Series2  800000 non-null  float64\n",
      " 2   Series3  800000 non-null  float64\n",
      " 3   Label    800000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 24.4 MB\n",
      "None\n",
      "\n",
      "Test Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   Series1  200000 non-null  float64\n",
      " 1   Series2  200000 non-null  float64\n",
      " 2   Series3  200000 non-null  float64\n",
      " 3   Label    200000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas -q\n",
    "!pip install denseweight\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from denseweight import DenseWeight\n",
    "\n",
    "\n",
    "# File paths\n",
    "train_file = \"./extraextra_lin_unchangedinp_log1p_train_data.csv\"\n",
    "test_file = \"./extraextra_lin_unchangedinp_log1p_test_data.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "dw = DenseWeight(alpha=0.75)\n",
    "print(pd.concat([train_df[\"Label\"], test_df[\"Label\"]]).to_numpy().shape)\n",
    "weights = dw.fit(pd.concat([train_df[\"Label\"], test_df[\"Label\"]]).to_numpy())\n",
    "train_weights = dw(train_df[\"Label\"].to_numpy())\n",
    "test_weights = dw(test_df[\"Label\"].to_numpy())\n",
    "\n",
    "print(dw([0.01]))\n",
    "print(dw([0.1]))\n",
    "print(dw([1]))\n",
    "print(dw([6]))\n",
    "print(dw([200]))\n",
    "print(dw([400]))\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Train Data:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series1</th>\n",
       "      <th>Series2</th>\n",
       "      <th>Series3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>8.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.002159</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.500670</td>\n",
       "      <td>2.498894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.632232</td>\n",
       "      <td>0.583146</td>\n",
       "      <td>0.291228</td>\n",
       "      <td>5.131788e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.346939</td>\n",
       "      <td>-0.494949</td>\n",
       "      <td>0.253273</td>\n",
       "      <td>4.289651e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.002121</td>\n",
       "      <td>-0.010101</td>\n",
       "      <td>0.505545</td>\n",
       "      <td>4.391191e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.346939</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.757818</td>\n",
       "      <td>3.308511e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.991320e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Series1        Series2        Series3         Label\n",
       "count  800000.000000  800000.000000  800000.000000  8.000000e+05\n",
       "mean       -0.002159       0.000114       0.500670  2.498894e-01\n",
       "std         2.632232       0.583146       0.291228  5.131788e-01\n",
       "min        -6.000000      -1.000000       0.001000  0.000000e+00\n",
       "25%        -1.346939      -0.494949       0.253273  4.289651e-09\n",
       "50%        -0.002121      -0.010101       0.505545  4.391191e-02\n",
       "75%         1.346939       0.515152       0.757818  3.308511e-01\n",
       "max         6.000000       1.000000       1.000000  5.991320e+00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sinabs in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pbr in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (6.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (2.2.2)\n",
      "Requirement already satisfied: torch>=1.8 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (2.4.1)\n",
      "Requirement already satisfied: nir in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (1.0.4)\n",
      "Requirement already satisfied: nirtorch in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (1.0)\n",
      "Requirement already satisfied: samna>=0.33 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (0.41.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (2024.12.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from nir->sinabs) (3.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from jinja2->torch>=1.8->sinabs) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sympy->torch>=1.8->sinabs) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install norse and pytorch\n",
    "!pip install sinabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.inputval = dataframe[\"Series1\"]\n",
    "        self.mean = dataframe[\"Series2\"]\n",
    "        self.std = dataframe[\"Series3\"]\n",
    "        self.labels = dataframe[\"Label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputval)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputval = self.inputval.iloc[idx]\n",
    "        mean = self.mean.iloc[idx]\n",
    "        std = self.std.iloc[idx]\n",
    "        labels = self.labels.iloc[idx]\n",
    "        return inputval, mean, std, labels\n",
    "    \n",
    "# Create the datasets\n",
    "train_dataset = DataFrameDataset(train_df)\n",
    "test_dataset = DataFrameDataset(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "train_sampler = WeightedRandomSampler(weights=train_weights, num_samples=len(train_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input data\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # , sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64) #, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 132865\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "TRAINING_PREFIX = \"extraextra_lin_256_2HL_log1p\"\n",
    "\n",
    "ann = nn.Sequential(\n",
    "    nn.Linear(3, 256),  # Input layer: 3 features (mu, sigma, x)\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),  # first hidden layer\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 256),  # second hidden layer\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 1)    # Output layer: single value for f(x; mu, sigma)\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "#ann.load_state_dict(torch.load(f\"results/{TRAINING_PREFIX}/ann_epoch_300.pth\"))\n",
    "\n",
    "ann.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in ann.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (spiking_model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "    (1): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (spike_output): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "  )\n",
       "  (analog_model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sinabs.from_torch import from_model\n",
    "\n",
    "num_time_steps_per_sample = 100\n",
    "\n",
    "sinabs_model = from_model(ann, input_shape=(3,), add_spiking_output=True, synops=False, num_timesteps=num_time_steps_per_sample)\n",
    "sinabs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torcheval -q\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "\n",
    "def create_loss_plot():\n",
    "    fig = go.FigureWidget()\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Train Loss', line=dict(color='blue')))\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Eval Loss', line=dict(color='orange')))\n",
    "\n",
    "    # Configure layout\n",
    "    fig.update_layout(title='Training and Evaluation Losses',\n",
    "                    xaxis_title='Epoch',\n",
    "                    yaxis_title='Loss',\n",
    "                    template='plotly_dark')\n",
    "\n",
    "    # Display the figure widget\n",
    "    display(fig)\n",
    "    return fig\n",
    "\n",
    "def update_loss_plot(fig, train_loss, eval_loss, from_epoch=0):\n",
    "    if from_epoch != 0:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(from_epoch, len(train_loss)))\n",
    "            fig.data[0].y = train_loss[from_epoch:]\n",
    "            fig.data[1].x = list(range(from_epoch, len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss[from_epoch:]\n",
    "    elif len(train_loss) < 30:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(len(train_loss)))\n",
    "            fig.data[0].y = train_loss\n",
    "            fig.data[1].x = list(range(len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss\n",
    "    else:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(len(train_loss) - 30, len(train_loss)))\n",
    "            fig.data[0].y = train_loss[-30:]\n",
    "            fig.data[1].x = list(range(len(eval_loss) - 30, len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss[-30:]        \n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "def gaussian_probability(x, y, z):\n",
    "    return (1 / (np.sqrt(2 * np.pi) * z)) * np.exp(-((x - y) ** 2) / (2 * z ** 2))\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def do_epoch(loader, model, optimizer, device, n_epochs: int, current_epoch: int, train: bool = False, scheduler=None):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    epoch_loss = 0\n",
    "    metric = R2Score(device=device)\n",
    "    for inputvals, means, stds, labels in tqdm(loader, desc=f\"{'Epoch' if train else 'Eval Epoch'} {current_epoch+1}/{n_epochs}\"):\n",
    "        inputs = torch.stack((inputvals, means, stds), dim=1).float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        metric.update(outputs.squeeze(), labels)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.huber_loss(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "        else:\n",
    "            loss = F.huber_loss(outputs.squeeze(), labels.float())\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # For Plateau scheduler\n",
    "    if scheduler is not None and not train:\n",
    "        print(\"sched step\")\n",
    "        scheduler.step(epoch_loss)\n",
    "    return epoch_loss, metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127c49e4419c48a69175fe2af1f476f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '1c03b424-b90e-40af-acbc-aaba87699e19',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'orange'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Eval Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'ae89a786-d2f7-4284-925d-9a0754e078a9',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Training and Evaluation Losses'},\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f033b455514e42ba767fd1a2ab4a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 630/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf8d1016dfc4d1aadf97401d374f7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 630/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 630, LR: [6.103515625e-09], Train Loss: 2.479790812515148e-06, Diff: -4.7079287583055e-10, Eval Loss: 5.5496209709872345e-06, Diff Eval: -2.214549294876629e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4072ca8780c4fee8d64e14b204be527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 631/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2f2a6a226843558aead202133a75e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 631/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 631, LR: [6.103515625e-09], Train Loss: 2.47953544039774e-06, Diff: -2.5537211740821365e-10, Eval Loss: 5.553941494235914e-06, Diff Eval: 4.320523248679681e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e04e8a77604fe4b725e896aa4c5a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 632/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7aac52767c4f9f8e8fa1f51afc9ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 632/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 632, LR: [6.103515625e-09], Train Loss: 2.4808864073258974e-06, Diff: 1.3509669281574276e-09, Eval Loss: 5.5591911238070676e-06, Diff Eval: 5.249629571153365e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391273a9c8034f4380e2526afc0ee0da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 633/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d82fbfc49141fb9ab9655d6fccbdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 633/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 633, LR: [6.103515625e-09], Train Loss: 2.48064817587192e-06, Diff: -2.382314539773627e-10, Eval Loss: 5.5557215845919926e-06, Diff Eval: -3.469539215074992e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b05f2df94142b8bd4db54faf132e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 634/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253799ebb95c4834b470a4bcaf641df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 634/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 634, LR: [6.103515625e-09], Train Loss: 2.4809669595163087e-06, Diff: 3.187836443886507e-10, Eval Loss: 5.553244693310262e-06, Diff Eval: -2.4768912817304685e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d23c58bd54b40c99051c8e5e2ddd286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 635/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685e5905acf7473080387354d1442c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 635/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 635, LR: [6.103515625e-09], Train Loss: 2.479228256747774e-06, Diff: -1.7387027685345039e-09, Eval Loss: 5.560262267995313e-06, Diff Eval: 7.017574685051138e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579191207886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330457bcd4ce468598305e44deebdf30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 636/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c8fcb210154336bb46586a46a3ba18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 636/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 636, LR: [6.103515625e-09], Train Loss: 2.4804650074509028e-06, Diff: 1.2367507031286069e-09, Eval Loss: 5.556340088314755e-06, Diff Eval: -3.922179680558112e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17a98c63c1a433fa3f8ac631409358b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 637/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4596fc52cc1348da8106e9f30ba98434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 637/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 637, LR: [6.103515625e-09], Train Loss: 2.482023615413027e-06, Diff: 1.558607962124394e-09, Eval Loss: 5.558706325082312e-06, Diff Eval: 2.3662367675567907e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b4784e553144ec9b3cb0d7bd733e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 638/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbb2c6378394e25970b3206c83b7bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 638/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 638, LR: [6.103515625e-09], Train Loss: 2.4801942891951965e-06, Diff: -1.8293262178306167e-09, Eval Loss: 5.5815481440367875e-06, Diff Eval: 2.284181895447557e-08, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.999957799911499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c0c30c27134074a3b2e69230d9776d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 639/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7736cf1cf3a340b7aad5f98b72ac0598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 639/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 639, LR: [6.103515625e-09], Train Loss: 2.4803137463572966e-06, Diff: 1.1945716210004953e-10, Eval Loss: 5.5805082377810325e-06, Diff Eval: -1.0399062557550252e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.999957799911499\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c0cfb43bc746879de8321984f0d1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 640/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b384ce21c3e49478f710d9380b59ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 640/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 640, LR: [6.103515625e-09], Train Loss: 2.4807599306120666e-06, Diff: 4.4618425476999606e-10, Eval Loss: 5.55745192154518e-06, Diff Eval: -2.3056316235852274e-08, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651a85cb22fb42168f5a290a0e5f15cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 641/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db2b8c4ed544bbabc5c0884be1ab035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 641/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 641, LR: [6.103515625e-09], Train Loss: 2.480943917219065e-06, Diff: 1.8398660699836742e-10, Eval Loss: 5.561579334225826e-06, Diff Eval: 4.1274126806456135e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579191207886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a41a2aebbda4d258adef474cd6cba06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 642/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0268ac31174b278b444baa5cc365c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 642/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 642, LR: [6.103515625e-09], Train Loss: 2.479148530354678e-06, Diff: -1.7953868643870852e-09, Eval Loss: 5.549559092514755e-06, Diff Eval: -1.2020241711070711e-08, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019d0f3403884c20a4bc3fd55ef71a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 643/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ef8975659b43df8490437995257ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 643/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 643, LR: [6.103515625e-09], Train Loss: 2.4792946161608144e-06, Diff: 1.4608580613649993e-10, Eval Loss: 5.5524879812992365e-06, Diff Eval: 2.9288887844814468e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2213c413b956415087785214f603fac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 644/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1980c82bdb14faf89d3f832e368875f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 644/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 644, LR: [6.103515625e-09], Train Loss: 2.4811931709893998e-06, Diff: 1.8985548285853963e-09, Eval Loss: 5.559996273523211e-06, Diff Eval: 7.508292223974507e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579191207886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c30af4c918a495a997c0f4ae25ad1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 645/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c61f57e896a46ab9699f19e8accc828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 645/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 645, LR: [6.103515625e-09], Train Loss: 2.4802272803549384e-06, Diff: -9.658906344613552e-10, Eval Loss: 5.550130848073422e-06, Diff Eval: -9.865425449788837e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffb81279e4349b48c3f199c5632ac0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 646/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0e7d97f8e5421c9d661459084923e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 646/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 646, LR: [6.103515625e-09], Train Loss: 2.4805581666021228e-06, Diff: 3.3088624718437224e-10, Eval Loss: 5.56136523209716e-06, Diff Eval: 1.123438402373746e-08, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579191207886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175abf1096024c60b1c0abd1d66bfcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 647/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faeb2d35f9cd41b884f667aa7deb4159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 647/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 647, LR: [6.103515625e-09], Train Loss: 2.482212228493381e-06, Diff: 1.6540618912582636e-09, Eval Loss: 5.549242515903643e-06, Diff Eval: -1.2122716193516625e-08, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fed74bba434091be9cb70954ecbcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 648/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbcad11b15f4b859c60af94fc5abfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 648/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 648, LR: [6.103515625e-09], Train Loss: 2.479237240772818e-06, Diff: -2.9749877205631107e-09, Eval Loss: 5.557835465187963e-06, Diff Eval: 8.592949284320112e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579787254333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f1da5ae85f4e2783d1d10269cf8ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 649/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a3c9d402c341ab8a03422f82c061fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 649/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 649, LR: [6.103515625e-09], Train Loss: 2.480282015112607e-06, Diff: 1.0447743397890348e-09, Eval Loss: 5.549269602556706e-06, Diff Eval: -8.565862631257499e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae744b6174945c985dcb33b52032666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 650/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620f2e1710ff4b74ba894cad90518c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 650/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 650, LR: [6.103515625e-09], Train Loss: 2.4811758639748403e-06, Diff: 8.938488622333629e-10, Eval Loss: 5.551834962452631e-06, Diff Eval: 2.565359895925385e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3aa8b8afaa459f91dc75515ecb4e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 651/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541a6d23316341d1a675845e87ca3e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 651/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 651, LR: [6.103515625e-09], Train Loss: 2.4788247785966176e-06, Diff: -2.3510853782227463e-09, Eval Loss: 5.54933477560553e-06, Diff Eval: -2.5001868471007254e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac78e89e1be473ca359b17a41c002d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 652/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e397de0a5d414b7092aa364a644f6b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 652/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 652, LR: [6.103515625e-09], Train Loss: 2.4808354032541046e-06, Diff: 2.0106246574870277e-09, Eval Loss: 5.549698824152074e-06, Diff Eval: 3.640485465438315e-10, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed20c7815b8b4054a0b90bd567be8596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 653/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53ccb7becd4476e8db0c4ef147b5b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 653/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 653, LR: [6.103515625e-09], Train Loss: 2.4817638151216668e-06, Diff: 9.284118675621692e-10, Eval Loss: 5.567359207961999e-06, Diff Eval: 1.7660383809925096e-08, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999579191207886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a044d307a54ad89fc5bda5642c2632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 654/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26dc6e9c24d94ad684467729d18409cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 654/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 654, LR: [6.103515625e-09], Train Loss: 2.4817148833085413e-06, Diff: -4.8931813125520715e-11, Eval Loss: 5.5476836211164484e-06, Diff Eval: -1.9675586845550802e-08, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea136019334483ea63b5bfb86248534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 655/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0735d204da844bbb805296c65ec9d7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 655/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sched step\n",
      "Epoch 655, LR: [6.103515625e-09], Train Loss: 2.480250081775921e-06, Diff: -1.4648015326202593e-09, Eval Loss: 5.54937692173553e-06, Diff Eval: 1.6933006190813103e-09, Train R2 Score: 0.999981164932251, Eval R2 Score: 0.9999580383300781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40998998160b4556b72637166a9eadd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 656/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     fig \u001b[38;5;241m=\u001b[39m create_loss_plot()\n\u001b[0;32m     46\u001b[0m     update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n\u001b[1;32m---> 48\u001b[0m epoch_loss, train_R2_score \u001b[38;5;241m=\u001b[39m \u001b[43mdo_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mann\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m eval_epoch_loss, eval_R2_score \u001b[38;5;241m=\u001b[39m do_epoch(test_loader, ann, \u001b[38;5;28;01mNone\u001b[39;00m, device, n_epochs\u001b[38;5;241m=\u001b[39mN_EPOCHS, current_epoch\u001b[38;5;241m=\u001b[39mepoch, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, scheduler\u001b[38;5;241m=\u001b[39mlr_scheduler)\n\u001b[0;32m     50\u001b[0m eval_loss_list\u001b[38;5;241m.\u001b[39mappend(eval_epoch_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_loader))\n",
      "Cell \u001b[1;32mIn[10], line 66\u001b[0m, in \u001b[0;36mdo_epoch\u001b[1;34m(loader, model, optimizer, device, n_epochs, current_epoch, train, scheduler)\u001b[0m\n\u001b[0;32m     64\u001b[0m metric \u001b[38;5;241m=\u001b[39m R2Score(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputvals, means, stds, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mtrain\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEval Epoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 66\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     67\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     68\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Scheduler\n",
    "!pip install pytorch_warmup\n",
    "\n",
    "from pytorch_warmup import LinearWarmup\n",
    "\n",
    "# Train\n",
    "\n",
    "ann.train()\n",
    "\n",
    "N_EPOCHS = 1000\n",
    "LR = 0.0004\n",
    "SAVE_EVERY = 50\n",
    "\n",
    "# Create subfolder for this loop\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(f\"./results/{TRAINING_PREFIX}\"):\n",
    "    shutil.rmtree(f\"./results/{TRAINING_PREFIX}\")\n",
    "os.makedirs(f\"./results/{TRAINING_PREFIX}\")\n",
    "\n",
    "optim = torch.optim.AdamW(ann.parameters(), lr=LR)\n",
    "#optim = torch.optim.SGD(ann.parameters(), lr=LR)\n",
    "#opt_step = torch.compile(optim.step, mode=\"reduce-overhead\")\n",
    "\n",
    "num_steps = len(train_loader) * N_EPOCHS\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.25, patience=10, verbose=True)\n",
    "#    optim,\n",
    "#    milestones=[i * len(train_loader) for i in [250, 500]])\n",
    "#warmup_scheduler = LinearWarmup(optim, warmup_period=(len(train_loader) * 50) )\n",
    "\n",
    "\n",
    "last_loss = 0\n",
    "last_eval_loss = 0\n",
    "\n",
    "epoch_loss_list = []\n",
    "eval_loss_list = [] \n",
    "\n",
    "fig = create_loss_plot()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        clear_output(wait=True)\n",
    "        fig = create_loss_plot()\n",
    "        update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n",
    "    \n",
    "    epoch_loss, train_R2_score = do_epoch(train_loader, ann, optim, device, n_epochs=N_EPOCHS, current_epoch=epoch, train=True, scheduler=lr_scheduler)\n",
    "    eval_epoch_loss, eval_R2_score = do_epoch(test_loader, ann, None, device, n_epochs=N_EPOCHS, current_epoch=epoch, train=False, scheduler=lr_scheduler)\n",
    "    eval_loss_list.append(eval_epoch_loss/len(test_loader))\n",
    "    print(f\"Epoch {epoch+1}, LR: {lr_scheduler.get_last_lr()}, Train Loss: {epoch_loss/len(train_loader)}, Diff: {epoch_loss/len(train_loader) - last_loss}, Eval Loss: {eval_epoch_loss/len(test_loader)}, Diff Eval: {eval_epoch_loss/len(test_loader) - last_eval_loss}, Train R2 Score: {train_R2_score}, Eval R2 Score: {eval_R2_score}\")\n",
    "    last_loss = epoch_loss/len(train_loader)\n",
    "    last_eval_loss = eval_epoch_loss/len(test_loader)\n",
    "    epoch_loss_list.append(epoch_loss/len(train_loader))\n",
    "    update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        torch.save(ann.state_dict(), f\"./results/{TRAINING_PREFIX}/ann_epoch_{epoch}.pth\")\n",
    "    elif epoch == N_EPOCHS - 1:\n",
    "        torch.save(ann.state_dict(), f\"./results/{TRAINING_PREFIX}/ann_epoch_{epoch}.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ann.state_dict(), \"largerer_ann_new_data5.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86aa2106be0b45bdb7f26065f9104065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '6c0504d7-16bb-41b8-975d-82ba5e5f2547',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'orange'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Eval Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '482614b7-0ffe-474c-bc86-1962277ccb6d',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Training and Evaluation Losses'},\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = create_loss_plot()\n",
    "update_loss_plot(fig, epoch_loss_list, eval_loss_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010720561613654717,\n",
       " 0.005650727769082005,\n",
       " 0.004973712196938722,\n",
       " 0.0046965876476417175,\n",
       " 0.00449116287927187,\n",
       " 0.0044736452529025705,\n",
       " 0.00434148402540508,\n",
       " 0.004304189840590843,\n",
       " 0.0043479884606443375,\n",
       " 0.004332168479999127,\n",
       " 0.004299884850940253,\n",
       " 0.004254439220912136,\n",
       " 0.00421730754099568,\n",
       " 0.004236685128641839,\n",
       " 0.004213748104372171,\n",
       " 0.004182607872355438,\n",
       " 0.004251838786280278,\n",
       " 0.004290557541898742,\n",
       " 0.0042712727683148115,\n",
       " 0.004242378014136594,\n",
       " 0.004250861869595573,\n",
       " 0.00425550736627858,\n",
       " 0.004341588957470994,\n",
       " 0.004267976844588484,\n",
       " 0.004295712128373216,\n",
       " 0.004355830985663124,\n",
       " 0.004358745869377599,\n",
       " 0.004367734752605648,\n",
       " 0.00434205544977729,\n",
       " 0.004377770489534632,\n",
       " 0.004356311271676313,\n",
       " 0.004363446383026967,\n",
       " 0.004342417285856391,\n",
       " 0.004399272141062902,\n",
       " 0.0034898571438213275,\n",
       " 0.0034030793314072253,\n",
       " 0.0033154675950014824,\n",
       " 0.0032616962320990662,\n",
       " 0.0032274479818930014,\n",
       " 0.0031887777890863343,\n",
       " 0.0032312808225748086,\n",
       " 0.003186244974969286,\n",
       " 0.003142077289710269,\n",
       " 0.00308836991676656,\n",
       " 0.0031501268893878477,\n",
       " 0.003071829233619901,\n",
       " 0.0029613876231700123,\n",
       " 0.003046518387771257,\n",
       " 0.0029380126937618932,\n",
       " 0.0030288542428452683,\n",
       " 0.0030546892481252597,\n",
       " 0.0029646702727787032,\n",
       " 0.0030064654080283254,\n",
       " 0.0030260115353737183,\n",
       " 0.0030802285160188604,\n",
       " 0.0029367349491015195,\n",
       " 0.0030331810249846513,\n",
       " 0.00297229657743118,\n",
       " 0.0030732204344043113,\n",
       " 0.002909453926165297,\n",
       " 0.00184349636336643,\n",
       " 0.0017160288140423382,\n",
       " 0.0015598136733186402,\n",
       " 0.0014594584704786667,\n",
       " 0.0013332908442240342,\n",
       " 0.0012450950796732377,\n",
       " 0.0011444517665917737,\n",
       " 0.001060498289376419,\n",
       " 0.0010143048225399525,\n",
       " 0.000955357102511034,\n",
       " 0.0009120352109900022,\n",
       " 0.0008752627270322592,\n",
       " 0.0008094612775091082,\n",
       " 0.0008079577795239493,\n",
       " 0.000763949306862894,\n",
       " 0.0007500941465135429,\n",
       " 0.0007228015683492026,\n",
       " 0.0007297985522217391,\n",
       " 0.0006582179470357642,\n",
       " 0.0006751064126622032,\n",
       " 0.0006846386920454893,\n",
       " 0.0006546963591514327,\n",
       " 0.0006815935342161356,\n",
       " 0.0006542214366541247,\n",
       " 0.0006417413698175779,\n",
       " 0.000621875602766313,\n",
       " 0.0006503423117648617,\n",
       " 0.0006129660248641812,\n",
       " 0.000615235631977414,\n",
       " 0.0006256206214607232,\n",
       " 0.0006053321898488184,\n",
       " 0.0006551957366780903,\n",
       " 0.0006051111730948355,\n",
       " 0.0005843598928037113,\n",
       " 0.0005910947048317053,\n",
       " 0.0006113600998177821,\n",
       " 0.0006438753259391069,\n",
       " 0.000629602965288384,\n",
       " 0.0005978604883869718,\n",
       " 0.000636985878706896,\n",
       " 0.0006012841819844516,\n",
       " 0.00018267336533823254,\n",
       " 0.0001631900251425634,\n",
       " 0.00016717481145168676,\n",
       " 0.00015694541484265529,\n",
       " 0.00015004518034111925,\n",
       " 0.00015315259225040336,\n",
       " 0.00014081366308454107,\n",
       " 0.00014297546666125073,\n",
       " 0.0001337579521171108,\n",
       " 0.0001340661371391434,\n",
       " 0.00013834412695478592,\n",
       " 0.00013286465521852506,\n",
       " 0.0001172896072239314,\n",
       " 0.0001237464316686021,\n",
       " 0.00012384136137300175,\n",
       " 0.00011643460283375248,\n",
       " 0.00011238737982460065,\n",
       " 0.0001172820877514414,\n",
       " 0.00010693193067884977,\n",
       " 0.0001089576289405818,\n",
       " 0.00010776645113508493,\n",
       " 0.00010393397301816549,\n",
       " 0.0001043362967618782,\n",
       " 0.0001036409627409057,\n",
       " 0.00010703349560175866,\n",
       " 9.359548743123924e-05,\n",
       " 0.00010266407553799581,\n",
       " 9.68008532481349e-05,\n",
       " 0.00010209574919498436,\n",
       " 9.755636151672548e-05,\n",
       " 9.364272464742499e-05,\n",
       " 9.86687701237645e-05,\n",
       " 9.617749976765594e-05,\n",
       " 9.507210747539603e-05,\n",
       " 9.193859858106748e-05,\n",
       " 9.058578733135051e-05,\n",
       " 8.64509479573985e-05,\n",
       " 9.490511625287012e-05,\n",
       " 8.476853810535658e-05,\n",
       " 8.994246299861743e-05,\n",
       " 8.516817408393764e-05,\n",
       " 9.050679859113871e-05,\n",
       " 8.741182018037761e-05,\n",
       " 8.541700191943733e-05,\n",
       " 8.491416762915037e-05,\n",
       " 3.4421263824119704e-05,\n",
       " 3.475893044564259e-05,\n",
       " 3.430956794316671e-05,\n",
       " 3.297109081779354e-05,\n",
       " 3.173341648723408e-05,\n",
       " 3.0374414407033328e-05,\n",
       " 3.093695383490172e-05,\n",
       " 3.013446979256969e-05,\n",
       " 2.994647807871388e-05,\n",
       " 2.814771394649142e-05,\n",
       " 2.761098283572551e-05,\n",
       " 2.7176190330926603e-05,\n",
       " 2.7096875873182853e-05,\n",
       " 2.5595360680869135e-05,\n",
       " 2.5407193301892904e-05,\n",
       " 2.4431439763727668e-05,\n",
       " 2.41158107243632e-05,\n",
       " 2.3446837196228215e-05,\n",
       " 2.3912399833156998e-05,\n",
       " 2.3202088841128443e-05,\n",
       " 2.209166133810072e-05,\n",
       " 2.1796723137177877e-05,\n",
       " 2.1456598681770627e-05,\n",
       " 2.140583123196393e-05,\n",
       " 2.1273583708218666e-05,\n",
       " 2.0698757811928773e-05,\n",
       " 2.007247258868574e-05,\n",
       " 2.0717660513000738e-05,\n",
       " 1.9344990570393746e-05,\n",
       " 1.907428295860427e-05,\n",
       " 1.8646634142669427e-05,\n",
       " 1.8726091495547053e-05,\n",
       " 1.789589729404497e-05,\n",
       " 1.8358605774783427e-05,\n",
       " 1.6908809254139213e-05,\n",
       " 1.7107906305243433e-05,\n",
       " 1.7021809972250138e-05,\n",
       " 1.6603028366535e-05,\n",
       " 1.6656845672038115e-05,\n",
       " 1.589361759000326e-05,\n",
       " 1.573801918917866e-05,\n",
       " 1.5632811077497308e-05,\n",
       " 1.5559528403102833e-05,\n",
       " 1.593589722815068e-05,\n",
       " 1.4896928024239741e-05,\n",
       " 1.455879374970209e-05,\n",
       " 1.452666095301197e-05,\n",
       " 1.4078343846464349e-05,\n",
       " 1.3917984975913668e-05,\n",
       " 1.3689369793712559e-05,\n",
       " 1.3719519843467652e-05,\n",
       " 1.3910536031293077e-05,\n",
       " 1.301622953242827e-05,\n",
       " 1.285610302737382e-05,\n",
       " 1.3666899186293904e-05,\n",
       " 1.2347088362431578e-05,\n",
       " 1.2677487856889229e-05,\n",
       " 1.2628551480321448e-05,\n",
       " 1.216059090139197e-05,\n",
       " 1.198275836805692e-05,\n",
       " 1.147809002290046e-05,\n",
       " 1.1913253593705804e-05,\n",
       " 1.1554218301821493e-05,\n",
       " 1.1769420330822413e-05,\n",
       " 1.1077285618272298e-05,\n",
       " 1.1208546145956007e-05,\n",
       " 1.0960982157453145e-05,\n",
       " 1.1410174030570488e-05,\n",
       " 1.0801883878517629e-05,\n",
       " 1.174143986221111e-05,\n",
       " 1.0912637924911905e-05,\n",
       " 1.0355892537888849e-05,\n",
       " 1.0440128692891904e-05,\n",
       " 1.025417301975267e-05,\n",
       " 9.82614200357034e-06,\n",
       " 1.0338459985625832e-05,\n",
       " 1.0025779492905258e-05,\n",
       " 9.832214912694325e-06,\n",
       " 1.0272864939745433e-05,\n",
       " 1.0032300457514793e-05,\n",
       " 1.0178155619593099e-05,\n",
       " 9.260079799364576e-06,\n",
       " 9.538542826732055e-06,\n",
       " 9.65167221737488e-06,\n",
       " 9.272985937849399e-06,\n",
       " 9.26714209670763e-06,\n",
       " 9.22906836289144e-06,\n",
       " 8.970321130941556e-06,\n",
       " 9.27971194710608e-06,\n",
       " 4.8132048072727684e-06,\n",
       " 4.795268452965047e-06,\n",
       " 4.774090203979995e-06,\n",
       " 4.790852576838915e-06,\n",
       " 4.6668195705194645e-06,\n",
       " 4.6967457990319874e-06,\n",
       " 4.611796371194714e-06,\n",
       " 4.604558005825084e-06,\n",
       " 4.672780097645273e-06,\n",
       " 4.603137559653305e-06,\n",
       " 4.561007293482362e-06,\n",
       " 4.480921623317044e-06,\n",
       " 4.543634175347506e-06,\n",
       " 4.399732775393659e-06,\n",
       " 4.439075351067458e-06,\n",
       " 4.42161280109076e-06,\n",
       " 4.448634041644936e-06,\n",
       " 4.36789581539415e-06,\n",
       " 4.349547003522502e-06,\n",
       " 4.386371868688457e-06,\n",
       " 4.27633903316746e-06,\n",
       " 4.320954802313963e-06,\n",
       " 4.327605683055253e-06,\n",
       " 4.28584959044656e-06,\n",
       " 4.2201263328718144e-06,\n",
       " 4.152029621532165e-06,\n",
       " 4.212134129866172e-06,\n",
       " 4.222588404967383e-06,\n",
       " 4.1882995562059475e-06,\n",
       " 4.1569635022653984e-06,\n",
       " 4.149941028902049e-06,\n",
       " 4.0820482115816505e-06,\n",
       " 4.110760004550684e-06,\n",
       " 3.996303315982459e-06,\n",
       " 4.067647214046701e-06,\n",
       " 4.017645031328811e-06,\n",
       " 4.0273909063364496e-06,\n",
       " 3.98881892043164e-06,\n",
       " 4.046696944106998e-06,\n",
       " 4.0175497385541805e-06,\n",
       " 3.909262199019849e-06,\n",
       " 3.908800654850211e-06,\n",
       " 3.891540430840905e-06,\n",
       " 3.83066515158589e-06,\n",
       " 3.8465079486877585e-06,\n",
       " 3.845464650970598e-06,\n",
       " 3.7966114048322197e-06,\n",
       " 3.827032141682594e-06,\n",
       " 3.7517501658589937e-06,\n",
       " 3.770440705352485e-06,\n",
       " 3.760935466521005e-06,\n",
       " 3.748481523564351e-06,\n",
       " 3.7103169606280063e-06,\n",
       " 3.7827599128047494e-06,\n",
       " 3.682715759970279e-06,\n",
       " 3.668435034741151e-06,\n",
       " 3.6835795277897885e-06,\n",
       " 3.628783342802535e-06,\n",
       " 3.6887857639408138e-06,\n",
       " 3.740937085084397e-06,\n",
       " 3.602136635338411e-06,\n",
       " 3.6176239451640413e-06,\n",
       " 3.6689033111406388e-06,\n",
       " 3.590714193126132e-06,\n",
       " 3.5859998816658843e-06,\n",
       " 3.557359777402098e-06,\n",
       " 3.5043281313642184e-06,\n",
       " 3.5942240444865093e-06,\n",
       " 3.5153074459969957e-06,\n",
       " 3.4765552158341963e-06,\n",
       " 3.531245229959268e-06,\n",
       " 3.4807454466806573e-06,\n",
       " 3.528904183689292e-06,\n",
       " 3.4419772127535e-06,\n",
       " 3.46310053422485e-06,\n",
       " 3.436128786053132e-06,\n",
       " 3.3503342625874664e-06,\n",
       " 3.3981114079983856e-06,\n",
       " 3.4307862102957644e-06,\n",
       " 3.3798092432709836e-06,\n",
       " 3.369514593957774e-06,\n",
       " 3.3231110931239983e-06,\n",
       " 3.30352730082609e-06,\n",
       " 3.2998060160139176e-06,\n",
       " 3.3303435067421107e-06,\n",
       " 3.2436085542235558e-06,\n",
       " 3.3086448975723216e-06,\n",
       " 3.3255856765686074e-06,\n",
       " 3.242440043680972e-06,\n",
       " 3.311062264423299e-06,\n",
       " 3.2441501426512785e-06,\n",
       " 3.272094320078622e-06,\n",
       " 3.277093806531184e-06,\n",
       " 3.2300256753865143e-06,\n",
       " 3.2256181545403707e-06,\n",
       " 3.243902430290291e-06,\n",
       " 3.2078024834913776e-06,\n",
       " 3.221032563009203e-06,\n",
       " 3.1504538664955815e-06,\n",
       " 3.1247620197450486e-06,\n",
       " 3.101960140073743e-06,\n",
       " 3.1609395437681086e-06,\n",
       " 3.0859218208718175e-06,\n",
       " 3.0846478153455335e-06,\n",
       " 3.0448150161612377e-06,\n",
       " 3.0879048354620408e-06,\n",
       " 3.0648799870414225e-06,\n",
       " 3.0720783638514606e-06,\n",
       " 3.078276668327362e-06,\n",
       " 3.0574231578077617e-06,\n",
       " 3.0122679081136993e-06,\n",
       " 3.074805804335483e-06,\n",
       " 3.094616614886263e-06,\n",
       " 2.6021255480372927e-06,\n",
       " 2.6161752694508778e-06,\n",
       " 2.606805458669896e-06,\n",
       " 2.604741078694133e-06,\n",
       " 2.6031113888609526e-06,\n",
       " 2.599072953846644e-06,\n",
       " 2.5941141182499904e-06,\n",
       " 2.592781084397302e-06,\n",
       " 2.5899126933541082e-06,\n",
       " 2.5843810127366852e-06,\n",
       " 2.5974998256424442e-06,\n",
       " 2.5833338225584158e-06,\n",
       " 2.58528830830187e-06,\n",
       " 2.5828124714610113e-06,\n",
       " 2.5078547311693456e-06,\n",
       " 2.50521235484257e-06,\n",
       " 2.50831921514191e-06,\n",
       " 2.504589054574353e-06,\n",
       " 2.5020596529441265e-06,\n",
       " 2.501678116381072e-06,\n",
       " 2.5020578960175042e-06,\n",
       " 2.502783585425732e-06,\n",
       " 2.504786191665289e-06,\n",
       " 2.500254336976013e-06,\n",
       " 2.5044238018563193e-06,\n",
       " 2.5006624406341873e-06,\n",
       " 2.4983748279657903e-06,\n",
       " 2.500499348714129e-06,\n",
       " 2.503804917123489e-06,\n",
       " 2.5048461005599164e-06,\n",
       " 2.4967346480150353e-06,\n",
       " 2.486132366725542e-06,\n",
       " 2.482258740127463e-06,\n",
       " 2.480909985334847e-06,\n",
       " 2.4793984840937356e-06,\n",
       " 2.479175087597696e-06,\n",
       " 2.480354804658873e-06,\n",
       " 2.479112117899831e-06,\n",
       " 2.4794240648952837e-06,\n",
       " 2.4808730944050692e-06,\n",
       " 2.478504066623373e-06,\n",
       " 2.4797800283965897e-06,\n",
       " 2.4791101336279554e-06,\n",
       " 2.4796542204938987e-06,\n",
       " 2.48058505898598e-06,\n",
       " 2.47938029245347e-06,\n",
       " 2.4799106356010727e-06,\n",
       " 2.4813126222716165e-06,\n",
       " 2.4798733446630193e-06,\n",
       " 2.4775256958525913e-06,\n",
       " 2.4816170956296444e-06,\n",
       " 2.4797269426903766e-06,\n",
       " 2.47777856343987e-06,\n",
       " 2.4799542136884157e-06,\n",
       " 2.479486580014054e-06,\n",
       " 2.4800628641287403e-06,\n",
       " 2.4811681247058457e-06,\n",
       " 2.4783852897746783e-06,\n",
       " 2.4796437693419195e-06,\n",
       " 2.4797079858421966e-06,\n",
       " 2.4808655577680837e-06,\n",
       " 2.4787044505171707e-06,\n",
       " 2.480763344174193e-06,\n",
       " 2.479675005241688e-06,\n",
       " 2.4815668279541116e-06,\n",
       " 2.479466137735926e-06,\n",
       " 2.481852148134749e-06,\n",
       " 2.480511875070306e-06,\n",
       " 2.4801275337790683e-06,\n",
       " 2.479591740160458e-06,\n",
       " 2.479563965982834e-06,\n",
       " 2.4802435747596974e-06,\n",
       " 2.4787264783913087e-06,\n",
       " 2.481345517196587e-06,\n",
       " 2.4808357643985347e-06,\n",
       " 2.480138568126904e-06,\n",
       " 2.4815791652258666e-06,\n",
       " 2.4809461082850247e-06,\n",
       " 2.4802337531480134e-06,\n",
       " 2.4800891730728836e-06,\n",
       " 2.478741727571787e-06,\n",
       " 2.478576508169681e-06,\n",
       " 2.4785480152741e-06,\n",
       " 2.4796744482114264e-06,\n",
       " 2.479011762961818e-06,\n",
       " 2.4814149945666486e-06,\n",
       " 2.4800839943759458e-06,\n",
       " 2.4796285253989936e-06,\n",
       " 2.4787888859577835e-06,\n",
       " 2.4783814803140557e-06,\n",
       " 2.4801244123648305e-06,\n",
       " 2.480097222069162e-06,\n",
       " 2.4802727415601568e-06,\n",
       " 2.4809209019053924e-06,\n",
       " 2.481276905897403e-06,\n",
       " 2.481184651506965e-06,\n",
       " 2.4799798851984176e-06,\n",
       " 2.4796368862280362e-06,\n",
       " 2.481231445387948e-06,\n",
       " 2.481819918276642e-06,\n",
       " 2.4793952584559518e-06,\n",
       " 2.4783099875435253e-06,\n",
       " 2.48080373042626e-06,\n",
       " 2.4785395836295265e-06,\n",
       " 2.481076902747645e-06,\n",
       " 2.480329050594037e-06,\n",
       " 2.4805161539165966e-06,\n",
       " 2.4784370232043785e-06,\n",
       " 2.480296195341225e-06,\n",
       " 2.478989220494441e-06,\n",
       " 2.4822091542739598e-06,\n",
       " 2.4787388890331385e-06,\n",
       " 2.4803282908578696e-06,\n",
       " 2.4786434407087653e-06,\n",
       " 2.478094680726599e-06,\n",
       " 2.4764068488934753e-06,\n",
       " 2.478572518847386e-06,\n",
       " 2.480054590032523e-06,\n",
       " 2.4797082458553634e-06,\n",
       " 2.4797357895727144e-06,\n",
       " 2.479513428684186e-06,\n",
       " 2.4800046006657795e-06,\n",
       " 2.4791108680381056e-06,\n",
       " 2.48085955776105e-06,\n",
       " 2.479129665127857e-06,\n",
       " 2.478854273314255e-06,\n",
       " 2.4774641149076615e-06,\n",
       " 2.478501558430253e-06,\n",
       " 2.480549570788071e-06,\n",
       " 2.479215171655369e-06,\n",
       " 2.481463440548168e-06,\n",
       " 2.4787528374895374e-06,\n",
       " 2.479190628220067e-06,\n",
       " 2.4780629913902884e-06,\n",
       " 2.4807550894604446e-06,\n",
       " 2.4787405881329507e-06,\n",
       " 2.480118657612138e-06,\n",
       " 2.480401940036927e-06,\n",
       " 2.4800158084565285e-06,\n",
       " 2.4805117500932285e-06,\n",
       " 2.4800079998419735e-06,\n",
       " 2.479475668125133e-06,\n",
       " 2.4798986859798333e-06,\n",
       " 2.4804432284258836e-06,\n",
       " 2.4794967856973925e-06,\n",
       " 2.481119109077099e-06,\n",
       " 2.4807078600747447e-06,\n",
       " 2.4801869497980532e-06,\n",
       " 2.479553006220385e-06,\n",
       " 2.4808299646167597e-06,\n",
       " 2.478261118045566e-06,\n",
       " 2.480983938811505e-06,\n",
       " 2.48111403398525e-06,\n",
       " 2.480878765832131e-06,\n",
       " 2.4801202786943576e-06,\n",
       " 2.4802367464462806e-06,\n",
       " 2.4781035998296375e-06,\n",
       " 2.4797651918368046e-06,\n",
       " 2.47902316288787e-06,\n",
       " 2.480877392761158e-06,\n",
       " 2.4807314082590894e-06,\n",
       " 2.480331968451992e-06,\n",
       " 2.477653684841243e-06,\n",
       " 2.4792650211827548e-06,\n",
       " 2.4794188242606198e-06,\n",
       " 2.4797962335117063e-06,\n",
       " 2.4791686576747905e-06,\n",
       " 2.479969399013271e-06,\n",
       " 2.479655892741448e-06,\n",
       " 2.4783791557661063e-06,\n",
       " 2.4816154543066205e-06,\n",
       " 2.4806090995070916e-06,\n",
       " 2.4794722473177445e-06,\n",
       " 2.4798711582218404e-06,\n",
       " 2.4793931410636104e-06,\n",
       " 2.478298852819307e-06,\n",
       " 2.480626285459948e-06,\n",
       " 2.480863106297875e-06,\n",
       " 2.4784400876671953e-06,\n",
       " 2.4788049832466186e-06,\n",
       " 2.4789758377846738e-06,\n",
       " 2.480609950843018e-06,\n",
       " 2.479737846870194e-06,\n",
       " 2.47834395741279e-06,\n",
       " 2.481614127730154e-06,\n",
       " 2.478529319033669e-06,\n",
       " 2.4821323388584913e-06,\n",
       " 2.4809097345985264e-06,\n",
       " 2.479955847202291e-06,\n",
       " 2.4801082924079766e-06,\n",
       " 2.4827463837164033e-06,\n",
       " 2.4822118064514596e-06,\n",
       " 2.4794670811206743e-06,\n",
       " 2.479152867181256e-06,\n",
       " 2.4798764767024296e-06,\n",
       " 2.478779310184791e-06,\n",
       " 2.480123962328662e-06,\n",
       " 2.4794367952995342e-06,\n",
       " 2.482523627804767e-06,\n",
       " 2.4813698379045946e-06,\n",
       " 2.481314743237135e-06,\n",
       " 2.479045699518565e-06,\n",
       " 2.4818478536963085e-06,\n",
       " 2.4815961670094565e-06,\n",
       " 2.481571070318296e-06,\n",
       " 2.480101500383398e-06,\n",
       " 2.4804397971911383e-06,\n",
       " 2.4807356664246073e-06,\n",
       " 2.4806953430129397e-06,\n",
       " 2.479872465594326e-06,\n",
       " 2.4791708495092734e-06,\n",
       " 2.47914311265049e-06,\n",
       " 2.4810769629300468e-06,\n",
       " 2.4803290440388535e-06,\n",
       " 2.481125228136989e-06,\n",
       " 2.4830583646439663e-06,\n",
       " 2.4806085605951014e-06,\n",
       " 2.4794304170848135e-06,\n",
       " 2.4803417934117534e-06,\n",
       " 2.481013343088989e-06,\n",
       " 2.479932481398919e-06,\n",
       " 2.4810704813558002e-06,\n",
       " 2.4809510016780224e-06,\n",
       " 2.4815333342473877e-06,\n",
       " 2.481179050157607e-06,\n",
       " 2.4811037189465424e-06,\n",
       " 2.481700567311691e-06,\n",
       " 2.48081438265217e-06,\n",
       " 2.4789325882443336e-06,\n",
       " 2.481799553070232e-06,\n",
       " 2.4803271770338144e-06,\n",
       " 2.480354696755285e-06,\n",
       " 2.4807402371482113e-06,\n",
       " 2.4806123472819764e-06,\n",
       " 2.479659924496218e-06,\n",
       " 2.48249046212095e-06,\n",
       " 2.480630788511462e-06,\n",
       " 2.4808224807657096e-06,\n",
       " 2.4794630494557167e-06,\n",
       " 2.4816120573700574e-06,\n",
       " 2.478991134721582e-06,\n",
       " 2.480597480157485e-06,\n",
       " 2.4813695060777265e-06,\n",
       " 2.481939266955351e-06,\n",
       " 2.4810548142204425e-06,\n",
       " 2.4797923053426984e-06,\n",
       " 2.480936229429744e-06,\n",
       " 2.4801017554716507e-06,\n",
       " 2.4816616166435777e-06,\n",
       " 2.4821714890413203e-06,\n",
       " 2.479509812211518e-06,\n",
       " 2.481675787998938e-06,\n",
       " 2.4786037066235166e-06,\n",
       " 2.4806247424317007e-06,\n",
       " 2.48219517065877e-06,\n",
       " 2.4816610295602004e-06,\n",
       " 2.479685329557242e-06,\n",
       " 2.4796796679970613e-06,\n",
       " 2.4827846293715085e-06,\n",
       " 2.481203381544219e-06,\n",
       " 2.4788274543448095e-06,\n",
       " 2.480042211145701e-06,\n",
       " 2.481090053719299e-06,\n",
       " 2.481456218361018e-06,\n",
       " 2.4819131931280936e-06,\n",
       " 2.4806054621080875e-06,\n",
       " 2.481339242665399e-06,\n",
       " 2.4791870941101023e-06,\n",
       " 2.4791346782092204e-06,\n",
       " 2.481567205942383e-06,\n",
       " 2.4815328033298558e-06,\n",
       " 2.479997907435063e-06,\n",
       " 2.479497121643135e-06,\n",
       " 2.4826019692170577e-06,\n",
       " 2.481036230385598e-06,\n",
       " 2.4786972853576117e-06,\n",
       " 2.4785341557287664e-06,\n",
       " 2.4789792502122053e-06,\n",
       " 2.4819147860046087e-06,\n",
       " 2.479941211724963e-06,\n",
       " 2.4802616053909787e-06,\n",
       " 2.479790812515148e-06,\n",
       " 2.47953544039774e-06,\n",
       " 2.4808864073258974e-06,\n",
       " 2.48064817587192e-06,\n",
       " 2.4809669595163087e-06,\n",
       " 2.479228256747774e-06,\n",
       " 2.4804650074509028e-06,\n",
       " 2.482023615413027e-06,\n",
       " 2.4801942891951965e-06,\n",
       " 2.4803137463572966e-06,\n",
       " 2.4807599306120666e-06,\n",
       " 2.480943917219065e-06,\n",
       " 2.479148530354678e-06,\n",
       " 2.4792946161608144e-06,\n",
       " 2.4811931709893998e-06,\n",
       " 2.4802272803549384e-06,\n",
       " 2.4805581666021228e-06,\n",
       " 2.482212228493381e-06,\n",
       " 2.479237240772818e-06,\n",
       " 2.480282015112607e-06,\n",
       " 2.4811758639748403e-06,\n",
       " 2.4788247785966176e-06,\n",
       " 2.4808354032541046e-06,\n",
       " 2.4817638151216668e-06,\n",
       " 2.4817148833085413e-06,\n",
       " 2.480250081775921e-06]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7985268002609114)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.eval()\n",
    "transformed = [[0.5, 0.5, 0.5]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7978845608028654)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.9791190668689422)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.1, 0.1, 0.1]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.989422804014327)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.1, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(41.86783290284835)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.01, 0.01, 0.01]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(39.894228040143275)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.01, 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4408715498811401)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.9, 0.9, 0.9]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.44326920044603635)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.9, 0.9, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5431544288899663)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.9, 0.7, 0.1]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.53990966513188)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.9, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.3789679900971876)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.643, 0.7, 0.1]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.3912431320419234)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.643, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.908748968321537e-05)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[4, 0.3, 0.2]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.57716245835995e-75)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(4, 0.3, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13131313, -0.23232323, -0.51515152,  0.43434343,  0.81818182,\n",
       "       -0.49494949, -0.81818182,  0.05050505,  0.15151515,  0.45454545,\n",
       "        0.35353535, -0.33333333,  0.09090909,  0.71717172, -0.97979798,\n",
       "        0.6969697 , -0.95959596, -0.83838384,  0.39393939,  0.7979798 ,\n",
       "        0.27272727, -0.43434343, -0.71717172, -0.93939394, -0.53535354,\n",
       "        0.75757576, -0.17171717, -0.39393939, -0.37373737, -0.45454545,\n",
       "        0.37373737, -0.21212121,  0.19191919, -0.09090909, -0.61616162,\n",
       "        0.53535354,  0.87878788, -0.87878788,  0.47474747, -0.85858586,\n",
       "       -0.13131313, -0.67676768, -0.03030303, -0.11111111,  0.73737374,\n",
       "       -0.63636364, -0.01010101, -0.7979798 ,  0.65656566,  0.95959596,\n",
       "       -0.73737374,  1.        , -0.5959596 ,  0.29292929,  0.49494949,\n",
       "        0.17171717,  0.25252525,  0.01010101, -0.29292929,  0.03030303,\n",
       "        0.8989899 ,  0.55555556,  0.67676768, -0.77777778, -0.31313131,\n",
       "        0.33333333,  0.51515152,  0.77777778,  0.41414141,  0.07070707,\n",
       "       -0.15151515,  0.57575758, -0.57575758,  0.61616162,  0.63636364,\n",
       "       -1.        , -0.65656566, -0.55555556,  0.91919192, -0.35353535,\n",
       "        0.83838384,  0.85858586,  0.97979798,  0.11111111,  0.93939394,\n",
       "        0.31313131, -0.91919192,  0.5959596 , -0.19191919, -0.25252525,\n",
       "       -0.6969697 , -0.27272727,  0.21212121, -0.47474747, -0.8989899 ,\n",
       "       -0.75757576, -0.07070707, -0.41414141,  0.23232323, -0.05050505])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.mean.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68718182, 0.23309091, 0.15236364, 0.92936364, 0.57618182,\n",
       "       0.97981818, 0.001     , 0.93945455, 0.04136364, 0.03127273,\n",
       "       0.98990909, 0.54590909, 0.09181818, 0.42481818, 0.56609091,\n",
       "       0.34409091, 0.14227273, 0.26336364, 0.01109091, 0.556     ,\n",
       "       0.71745455, 0.81836364, 0.59636364, 0.45509091, 0.47527273,\n",
       "       0.112     , 0.60645455, 0.61654545, 0.43490909, 0.69727273,\n",
       "       0.75781818, 0.46518182, 0.82845455, 0.32390909, 0.16245455,\n",
       "       0.91927273, 0.18263636, 0.29363636, 0.63672727, 0.76790909,\n",
       "       0.96972727, 0.58627273, 0.74772727, 0.86881818, 0.36427273,\n",
       "       0.90918182, 0.889     , 0.12209091, 0.27345455, 0.73763636,\n",
       "       0.62663636, 0.65690909, 0.49545455, 0.87890909, 0.10190909,\n",
       "       0.778     , 0.89909091, 0.17254545, 0.20281818, 0.48536364,\n",
       "       0.08172727, 0.94954545, 0.24318182, 0.50554545, 0.41472727,\n",
       "       0.667     , 0.31381818, 0.39454545, 0.25327273, 0.37436364,\n",
       "       0.05145455, 0.51563636, 0.21290909, 0.334     , 1.        ,\n",
       "       0.83854545, 0.35418182, 0.02118182, 0.30372727, 0.223     ,\n",
       "       0.84863636, 0.38445455, 0.79818182, 0.52572727, 0.80827273,\n",
       "       0.445     , 0.64681818, 0.28354545, 0.67709091, 0.78809091,\n",
       "       0.07163636, 0.95963636, 0.19272727, 0.70736364, 0.13218182,\n",
       "       0.06154545, 0.40463636, 0.72754545, 0.85872727, 0.53581818])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.std.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.20334854540768302)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# std 1.25 and mean -3.04\n",
    "transformed = [[-2, -3.04, 1.25]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22578002723581)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(-2, -3.04, 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(242.76307435675864)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[0.999, 1, 0.001]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(241.97072451914318)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.999, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(397.1416407205497)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = [[1, 1, 0.001]]\n",
    "tensor = torch.tensor(transformed).to(device).float()\n",
    "np.expm1(ann(tensor).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(398.94228040143275)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(1, 1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
