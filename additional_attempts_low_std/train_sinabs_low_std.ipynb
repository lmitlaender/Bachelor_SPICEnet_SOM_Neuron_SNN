{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800000 entries, 0 to 799999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   Series1  800000 non-null  float64\n",
      " 1   Series2  800000 non-null  float64\n",
      " 2   Series3  800000 non-null  float64\n",
      " 3   Label    800000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 24.4 MB\n",
      "None\n",
      "\n",
      "Test Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   Series1  200000 non-null  float64\n",
      " 1   Series2  200000 non-null  float64\n",
      " 2   Series3  200000 non-null  float64\n",
      " 3   Label    200000 non-null  float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas -q\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "train_file = \"./train_final_method_very_low_std.csv\"\n",
    "test_file = \"./test_final_method_very_low_std.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"Train Data:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series1</th>\n",
       "      <th>Series2</th>\n",
       "      <th>Series3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>8.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.008498</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>3.143162</td>\n",
       "      <td>1.529899e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.678629</td>\n",
       "      <td>1.832007</td>\n",
       "      <td>1.831380</td>\n",
       "      <td>2.137374e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-34.557519</td>\n",
       "      <td>-3.141593</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.419294</td>\n",
       "      <td>-1.554930</td>\n",
       "      <td>1.587410</td>\n",
       "      <td>1.487715e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.001999</td>\n",
       "      <td>-0.031733</td>\n",
       "      <td>3.173821</td>\n",
       "      <td>3.667494e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.422526</td>\n",
       "      <td>1.618396</td>\n",
       "      <td>4.760231</td>\n",
       "      <td>9.637206e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.557519</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>6.283185</td>\n",
       "      <td>3.989423e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Series1        Series2        Series3         Label\n",
       "count  800000.000000  800000.000000  800000.000000  8.000000e+05\n",
       "mean       -0.008498       0.000357       3.143162  1.529899e+00\n",
       "std        14.678629       1.832007       1.831380  2.137374e+01\n",
       "min       -34.557519      -3.141593       0.001000  0.000000e+00\n",
       "25%        -5.419294      -1.554930       1.587410  1.487715e-08\n",
       "50%        -0.001999      -0.031733       3.173821  3.667494e-02\n",
       "75%         5.422526       1.618396       4.760231  9.637206e-02\n",
       "max        34.557519       3.141593       6.283185  3.989423e+02"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sinabs in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: pbr in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (6.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (2.2.2)\n",
      "Requirement already satisfied: torch>=1.8 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (2.4.1)\n",
      "Requirement already satisfied: nir in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (1.0.4)\n",
      "Requirement already satisfied: nirtorch in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (1.0)\n",
      "Requirement already satisfied: samna>=0.33 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sinabs) (0.41.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from torch>=1.8->sinabs) (2024.12.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from nir->sinabs) (3.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from jinja2->torch>=1.8->sinabs) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lutz\\bachelorarbeit2\\snn\\.venv\\lib\\site-packages (from sympy->torch>=1.8->sinabs) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install norse and pytorch\n",
    "!pip install sinabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.inputval = dataframe[\"Series1\"]\n",
    "        self.mean = dataframe[\"Series2\"]\n",
    "        self.std = dataframe[\"Series3\"]\n",
    "        self.labels = dataframe[\"Label\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputval)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputval = self.inputval.iloc[idx]\n",
    "        mean = self.mean.iloc[idx]\n",
    "        std = self.std.iloc[idx]\n",
    "        labels = self.labels.iloc[idx]\n",
    "        return inputval, mean, std, labels\n",
    "    \n",
    "# Create the datasets\n",
    "train_dataset = DataFrameDataset(train_df)\n",
    "test_dataset = DataFrameDataset(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy\n",
    "\n",
    "#num_bins = 4/0.01\n",
    "\n",
    "#min_val = float(train_dataset.labels.min())\n",
    "#max_val = float(train_dataset.labels.max())\n",
    "\n",
    "#bins_train = torch.linspace(min_val, max_val, int(num_bins + 1))\n",
    "#bin_indices_train = numpy.digitize(train_dataset.labels, bins_train, right=True)\n",
    "##print(bin_indices_train)\n",
    "#bin_counts = torch.bincount(torch.tensor(bin_indices_train))\n",
    "\n",
    "# plot bin_counts\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.hist(bin_counts)\n",
    "#plt.show()\n",
    "#bin_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the weights for each bin\n",
    "\n",
    "#bin_weights = 1.0 / (bin_counts + 1e-6)  # Inverse of bin counts\n",
    "#plt.hist(bin_weights)\n",
    "#plt.show()\n",
    "#print(len(bin_weights))\n",
    "#print(\"Summed: \", sum(bin_weights))\n",
    "#sample_weights = bin_weights[bin_indices]  # Assign weights to each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "#sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input data\n",
    "train_loader = DataLoader(train_dataset, batch_size=64) #, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64) #, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 132865\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "TRAINING_PREFIX = \"final_low_std\"\n",
    "\n",
    "ann = nn.Sequential(\n",
    "    nn.Linear(3, 256),  # Input layer: 3 features (mu, sigma, x)\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.2),\n",
    "    nn.Linear(256, 256),  # first hidden layer\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.2),\n",
    "    nn.Linear(256, 256),  # second hidden layer\n",
    "    nn.ReLU(),\n",
    "    #nn.Dropout(0.2),\n",
    "    nn.Linear(256, 1)    # Output layer: single value for f(x; mu, sigma)\n",
    ")\n",
    "\n",
    "#ann.load_state_dict(torch.load(\"largerer_ann_new_data4.pth\"))\n",
    "\n",
    "ann.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in ann.parameters() if p.requires_grad)\n",
    "print(f\"Total Parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (spiking_model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "    (1): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (spike_output): IAFSqueeze(spike_threshold=Parameter containing:\n",
       "    tensor(1.), min_v_mem=Parameter containing:\n",
       "    tensor(-1.), batch_size=-1, num_timesteps=100)\n",
       "  )\n",
       "  (analog_model): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sinabs.from_torch import from_model\n",
    "\n",
    "num_time_steps_per_sample = 100\n",
    "\n",
    "sinabs_model = from_model(ann, input_shape=(3,), add_spiking_output=True, synops=False, num_timesteps=num_time_steps_per_sample)\n",
    "sinabs_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "\n",
    "def create_loss_plot():\n",
    "    fig = go.FigureWidget()\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Train Loss', line=dict(color='blue')))\n",
    "    fig.add_trace(go.Scatter(x=[], y=[], mode='lines', name='Eval Loss', line=dict(color='orange')))\n",
    "\n",
    "    # Configure layout\n",
    "    fig.update_layout(title='Training and Evaluation Losses',\n",
    "                    xaxis_title='Epoch',\n",
    "                    yaxis_title='Loss',\n",
    "                    template='plotly_dark')\n",
    "\n",
    "    # Display the figure widget\n",
    "    display(fig)\n",
    "    return fig\n",
    "\n",
    "def update_loss_plot(fig, train_loss, eval_loss, from_epoch=0):\n",
    "    if from_epoch != 0:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(from_epoch, len(train_loss)))\n",
    "            fig.data[0].y = train_loss[from_epoch:]\n",
    "            fig.data[1].x = list(range(from_epoch, len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss[from_epoch:]\n",
    "    elif len(train_loss) < 30:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(len(train_loss)))\n",
    "            fig.data[0].y = train_loss\n",
    "            fig.data[1].x = list(range(len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss\n",
    "    else:\n",
    "        with fig.batch_update():\n",
    "            fig.data[0].x = list(range(len(train_loss) - 30, len(train_loss)))\n",
    "            fig.data[0].y = train_loss[-30:]\n",
    "            fig.data[1].x = list(range(len(eval_loss) - 30, len(eval_loss)))\n",
    "            fig.data[1].y = eval_loss[-30:]        \n",
    "    \n",
    "\n",
    "import numpy as np\n",
    "def gaussian_probability(x, y, z):\n",
    "    return (1 / (np.sqrt(2 * np.pi) * z)) * np.exp(-((x - y) ** 2) / (2 * z ** 2))\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def do_epoch(loader, model, optimizer, device, n_epochs: int, current_epoch: int, train: bool = False,):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    epoch_loss = 0\n",
    "    metric = R2Score(device=device)\n",
    "    for inputvals, means, stds, labels in tqdm(loader, desc=f\"{'Epoch' if train else 'Eval Epoch'} {current_epoch+1}/{n_epochs}\"):\n",
    "        inputs = torch.stack((inputvals, means, stds), dim=1).float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        metric.update(outputs.squeeze(), labels)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.mse_loss(outputs.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            loss = F.mse_loss(outputs.squeeze(), labels.float())\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss, metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef2168547d64b7d8a10cabb5e8a8116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '906a59cd-91de-4939-9e85-c4a79562bfa6',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'orange'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Eval Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': '19ef21c2-7515-4b38-9558-5569af3a38f4',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Training and Evaluation Losses'},\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d36d722b2f40a49fc9a6b2c2199f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 501/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08955ac12954c378d733a7b74f3b58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval Epoch 501/1000:   0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 501, Train Loss: nan, Diff: nan, Eval Loss: nan, Diff Eval: nan, Train R2 Score: nan, Eval R2 Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\jupyter_client\\session.py:721: UserWarning:\n",
      "\n",
      "Message serialization failed with:\n",
      "Out of range float values are not JSON compliant\n",
      "Supporting this message is deprecated in jupyter-client 7, please make sure your message is JSON-compliant\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c283d808c041b29be5add0105c8002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 502/1000:   0%|          | 0/12500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     fig \u001b[38;5;241m=\u001b[39m create_loss_plot()\n\u001b[0;32m     32\u001b[0m     update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n\u001b[1;32m---> 34\u001b[0m epoch_loss, train_R2_score \u001b[38;5;241m=\u001b[39m \u001b[43mdo_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mann\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m eval_epoch_loss, eval_R2_score \u001b[38;5;241m=\u001b[39m do_epoch(test_loader, ann, \u001b[38;5;28;01mNone\u001b[39;00m, device, n_epochs\u001b[38;5;241m=\u001b[39mN_EPOCHS, current_epoch\u001b[38;5;241m=\u001b[39mepoch, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     36\u001b[0m eval_loss_list\u001b[38;5;241m.\u001b[39mappend(eval_epoch_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_loader))\n",
      "Cell \u001b[1;32mIn[13], line 72\u001b[0m, in \u001b[0;36mdo_epoch\u001b[1;34m(loader, model, optimizer, device, n_epochs, current_epoch, train)\u001b[0m\n\u001b[0;32m     70\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     71\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(outputs\u001b[38;5;241m.\u001b[39msqueeze(), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m---> 72\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lutz\\Bachelorarbeit2\\SNN\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ann.train()\n",
    "\n",
    "N_EPOCHS = 500\n",
    "LR = 0.00001\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "SAVE_EVERY = 50\n",
    "\n",
    "# Create subfolder for this loop\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(f\"./results/{TRAINING_PREFIX}\"):\n",
    "    shutil.rmtree(f\"./results/{TRAINING_PREFIX}\")\n",
    "os.makedirs(f\"./results/{TRAINING_PREFIX}\")\n",
    "\n",
    "#optim = torch.optim.Adam(ann.parameters(), lr=LR)\n",
    "optim = torch.optim.SGD(ann.parameters(), lr=LR, momentum=MOMENTUM, nesterov=NESTEROV)\n",
    "\n",
    "last_loss = 0\n",
    "last_eval_loss = 0\n",
    "\n",
    "epoch_loss_list = []\n",
    "eval_loss_list = [] \n",
    "\n",
    "fig = create_loss_plot()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    if (epoch + 1) % 30 == 0:\n",
    "        clear_output(wait=True)\n",
    "        fig = create_loss_plot()\n",
    "        update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n",
    "    \n",
    "    epoch_loss, train_R2_score = do_epoch(train_loader, ann, optim, device, n_epochs=N_EPOCHS, current_epoch=epoch, train=True)\n",
    "    eval_epoch_loss, eval_R2_score = do_epoch(test_loader, ann, None, device, n_epochs=N_EPOCHS, current_epoch=epoch, train=False)\n",
    "    eval_loss_list.append(eval_epoch_loss/len(test_loader))\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss/len(train_loader)}, Diff: {epoch_loss/len(train_loader) - last_loss}, Eval Loss: {eval_epoch_loss/len(test_loader)}, Diff Eval: {eval_epoch_loss/len(test_loader) - last_eval_loss}, Train R2 Score: {train_R2_score}, Eval R2 Score: {eval_R2_score}\")\n",
    "    last_loss = epoch_loss/len(train_loader)\n",
    "    last_eval_loss = eval_epoch_loss/len(test_loader)\n",
    "    epoch_loss_list.append(epoch_loss/len(train_loader))\n",
    "    update_loss_plot(fig, epoch_loss_list, eval_loss_list)\n",
    "    if epoch % SAVE_EVERY == 0:\n",
    "        torch.save(ann.state_dict(), f\"./results/{TRAINING_PREFIX}/ann_epoch_{epoch}.pth\")\n",
    "    elif epoch == N_EPOCHS - 1:\n",
    "        torch.save(ann.state_dict(), f\"./results/{TRAINING_PREFIX}/ann_epoch_{epoch}.pth\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(ann.state_dict(), \"largerer_ann_new_data5.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b81111ffff47e881cf74c97f163a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'line': {'color': 'blue'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Train Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'f4e1ee4f-7170-4425-8c6a-a2999e57519f',\n",
       "              'x': [],\n",
       "              'y': []},\n",
       "             {'line': {'color': 'orange'},\n",
       "              'mode': 'lines',\n",
       "              'name': 'Eval Loss',\n",
       "              'type': 'scatter',\n",
       "              'uid': 'b5581eb1-4326-4b14-ba63-c8419c5020fc',\n",
       "              'x': [],\n",
       "              'y': []}],\n",
       "    'layout': {'template': '...',\n",
       "               'title': {'text': 'Training and Evaluation Losses'},\n",
       "               'xaxis': {'title': {'text': 'Epoch'}},\n",
       "               'yaxis': {'title': {'text': 'Loss'}}}\n",
       "})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = create_loss_plot()\n",
    "update_loss_plot(fig, epoch_loss_list, eval_loss_list, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.eval()\n",
    "ann(torch.tensor([[0.5, 0.5, 0.5]]).to(device)).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7978845608028654)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.5, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann(torch.tensor([[0.1, 0.1, 0.1]]).to(device)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.989422804014327)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.1, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4560743570327759"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann(torch.tensor([[0.9, 0.9, 0.9]]).to(device)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.44326920044603635)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.9, 0.9, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.061571717262268"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann(torch.tensor([[0.9, 0.7, 0.1]]).to(device)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.53990966513188)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.9, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.877206802368164"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann(torch.tensor([[0.643, 0.7, 0.1]]).to(device)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.3912431320419234)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(0.643, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01944279670715332"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann(torch.tensor([[4, 0.3, 0.2]]).to(device)).item() # Not really generalized to computation of f(x; mu, sigma), but learned kind of in the ranges the data existed in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.57716245835995e-75)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(4, 0.3, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.41253237, -0.72986496, -1.61839622,  1.36453014,  2.57039399,\n",
       "       -1.5549297 , -2.57039399,  0.1586663 ,  0.47599889,  1.42799666,\n",
       "        1.11066407, -1.04719755,  0.28559933,  2.2530614 , -3.07812614,\n",
       "        2.18959488, -3.01465962, -2.63386051,  1.23759711,  2.50692747,\n",
       "        0.856798  , -1.36453014, -2.2530614 , -2.9511931 , -1.68186273,\n",
       "        2.37999443, -0.53946541, -1.23759711, -1.17413059, -1.42799666,\n",
       "        1.17413059, -0.66639844,  0.60293192, -0.28559933, -1.93572881,\n",
       "        1.68186273,  2.76079354, -2.76079354,  1.49146318, -2.69732703,\n",
       "       -0.41253237, -2.12612836, -0.09519978, -0.34906585,  2.31652792,\n",
       "       -1.99919533, -0.03173326, -2.50692747,  2.06266184,  3.01465962,\n",
       "       -2.31652792,  3.14159265, -1.87226229,  0.92026451,  1.5549297 ,\n",
       "        0.53946541,  0.79333148,  0.03173326, -0.92026451,  0.09519978,\n",
       "        2.82426006,  1.74532925,  2.12612836, -2.44346095, -0.98373103,\n",
       "        1.04719755,  1.61839622,  2.44346095,  1.30106362,  0.22213281,\n",
       "       -0.47599889,  1.80879577, -1.80879577,  1.93572881,  1.99919533,\n",
       "       -3.14159265, -2.06266184, -1.74532925,  2.88772658, -1.11066407,\n",
       "        2.63386051,  2.69732703,  3.07812614,  0.34906585,  2.9511931 ,\n",
       "        0.98373103, -2.88772658,  1.87226229, -0.60293192, -0.79333148,\n",
       "       -2.18959488, -0.856798  ,  0.66639844, -1.49146318, -2.82426006,\n",
       "       -2.37999443, -0.22213281, -1.30106362,  0.72986496, -0.1586663 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.mean.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.31603637e+00, 1.46049760e+00, 9.52846259e-01, 5.83899039e+00,\n",
       "       3.61801578e+00, 6.15627247e+00, 1.00000000e-03, 5.90244680e+00,\n",
       "       2.54825669e-01, 1.91369252e-01, 6.21972889e+00, 3.42764653e+00,\n",
       "       5.72107755e-01, 2.66616952e+00, 3.55455937e+00, 2.15851819e+00,\n",
       "       8.89389841e-01, 1.65086685e+00, 6.44564172e-02, 3.49110295e+00,\n",
       "       4.50640562e+00, 5.14096980e+00, 3.74492862e+00, 2.85653878e+00,\n",
       "       2.98345161e+00, 6.99020590e-01, 3.80838503e+00, 3.87184145e+00,\n",
       "       2.72962594e+00, 4.37949279e+00, 4.76023129e+00, 2.91999519e+00,\n",
       "       5.20442621e+00, 2.03160535e+00, 1.01630268e+00, 5.77553397e+00,\n",
       "       1.14321551e+00, 1.84123610e+00, 3.99875429e+00, 4.82368771e+00,\n",
       "       6.09281606e+00, 3.68147220e+00, 4.69677488e+00, 5.45825188e+00,\n",
       "       2.28543102e+00, 5.71207755e+00, 5.58516472e+00, 7.62477007e-01,\n",
       "       1.71432327e+00, 4.63331846e+00, 3.93529787e+00, 4.12566712e+00,\n",
       "       3.11036444e+00, 5.52170830e+00, 6.35564172e-01, 4.88714413e+00,\n",
       "       5.64862113e+00, 1.07975909e+00, 1.27012834e+00, 3.04690803e+00,\n",
       "       5.08651338e-01, 5.96590322e+00, 1.52395401e+00, 3.17382086e+00,\n",
       "       2.60271311e+00, 4.18912354e+00, 1.96814893e+00, 2.47580027e+00,\n",
       "       1.58741043e+00, 2.34888744e+00, 3.18282086e-01, 3.23727728e+00,\n",
       "       1.33358476e+00, 2.09506177e+00, 6.28318531e+00, 5.26788263e+00,\n",
       "       2.22197460e+00, 1.27912834e-01, 1.90469252e+00, 1.39704118e+00,\n",
       "       5.33133905e+00, 2.41234386e+00, 5.01405696e+00, 3.30073370e+00,\n",
       "       5.07751338e+00, 2.79308236e+00, 4.06221070e+00, 1.77777968e+00,\n",
       "       4.25257996e+00, 4.95060055e+00, 4.45194921e-01, 6.02935964e+00,\n",
       "       1.20667193e+00, 4.44294921e+00, 8.25933424e-01, 3.81738503e-01,\n",
       "       2.53925669e+00, 4.56986204e+00, 5.39479547e+00, 3.36419011e+00])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.std.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24668222665786743"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# std 1.25 and mean -3.04\n",
    "ann(torch.tensor([[-2, -3.04, 1.25]]).to(device)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.22578002723581)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(-2, -3.04, 1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.79"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-3.04 - 3 * 1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.7752990722656"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann(torch.tensor([[-3.04, -3.04, 0.001]]).to(device)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(398.94228040143275)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_probability(-3.04, -3.04, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
